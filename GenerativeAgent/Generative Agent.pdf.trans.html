<!DOCTYPE html><head><meta charset="utf-8"><title>翻译结果</title><style>
.row {
  display: flex;
  flex-wrap: wrap;
}

.column {
  flex: 1;
  padding: 10px;
}

.table-header {
  font-weight: bold;
  border-bottom: 1px solid black;
}

.table-row {
  border-bottom: 1px solid lightgray;
}

.table-cell {
  padding: 5px;
}
        </style></head>
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"></div></div>
    <div class="column table-cell"><div class="markdown-body"></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>一、论文概况</p></div></div>
    <div class="column table-cell"><div class="markdown-body"></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>Abstract</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>题目：生成式智能体：人类行为的交互模拟</p>
<p>摘要：图1：生成式智能体是用于交互性应用的可信模拟的人类行为。在这项工作中，我们通过在一个沙盒环境中添加二十五个智能体，使其与《模拟人生》类似，展示了生成式智能体的功能。用户可以观察和干预智能体的日常计划、新闻分享、人际关系形成和团队协作。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><p>二、论文翻译</p></div></div>
    <div class="column table-cell"><div class="markdown-body"></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1></h1>
<p>authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>作者们写道，他们形成观点，相互注意，并发起对话；他们回忆和反思过去的日子，同时规划未来。为了实现生成式智能体，我们描述了一个架构，通过扩展大型语言模型来存储智能体以自然语言记录的完整经历，将这些记忆随着时间推移综合成更高层次的反思，并动态地检索它们以规划行为。我们实例化了生成式智能体，用自然语言与这个受到《模拟人生》启发的互动沙盒环境中的二十五个智能体进行交互。在评估中，这些生成式智能体表现出可信的个体和 emergent (出现的) 社会行为。例如，仅仅从一个用户指定一个智能体想要举办情人节派对的概念开始，智能体自主地在接下来的两天内传播了派对的邀请。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>INTRODUCTION Part-1</h1>
<p>How might we craft an interactive artificial society that reflects believable human behavior? From sandbox games such as The Sims to applications such as cognitive models [23] and virtual environments [10,59], for over four decades, researchers and practitioners have envisioned computational agents that can serve as believable proxies of human behavior. In these visions, computationallypowered agents act consistently with their past experiences and react believably to their environments. Such simulations of human behavior could populate virtual spaces and communities with realistic social phenomena [27,80], train people on how to handle rare yet difficult interpersonal situations [44,52,94], test social science theories [12,46], craft model human processors for theory and usability testing [23,39,51], power ubiquitous computing applications [31] and social robots [10,14], and underpin non-playable game characters [59,85] that can navigate complex human relationships in an open world.
However, the space of human behavior is vast and complex [85,108]. Despite striking progress in large language models [18] that can simulate human behavior at a single time point [39,80], fully general agents that ensure long-term coherence would be better suited by architectures that manage constantly-growing memories as new interactions, conflicts, and events arise and fade over time while handling cascading social dynamics that unfold between multiple agents. Success requires an approach that can retrieve relevant events and interactions over a long period, reflect on those memories to generalize and draw higher-level inferences, and apply that reasoning to create plans and reactions that make sense in the moment and in the longer-term arc of the agent's behavior.
In this paper, we introduce generative agents-agents that draw on generative models to simulate believable human behavior-and demonstrate that they produce believable simulacra of both individual and emergent group behavior. Generative agents draw a wide variety of inferences about themselves, other agents, and their environment; they create daily plans that reflect their characteristics and experiences, act out those plans, react, and re-plan when appropriate; they respond when the end user changes their environment or commands them in natural language. For instance, generative agents turn off the stove when they see that their breakfast is burning, wait outside the bathroom if it is occupied, and stop to chat when they meet another agent they want to talk to. 1A society full of generative agents is marked by emergent social dynamics where new relationships are formed, information diffuses, and coordination arises across agents.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>第一部分：介绍</p>
<p>我们如何创建一个反映可信人类行为的交互式人工社会？从沙盒游戏《模拟人生》到认知模型和虚拟环境等应用 [23, 10, 59]，在过去的四十年里，研究人员和实践者们一直设想能够作为可信人类行为代理的计算机代理。在这些设想中，计算机支持的代理根据其过去的经验始终一致地行动，并对其环境作出可信反应。这样的人类行为模拟可以在虚拟空间和社区中填充真实的社会现象 [27, 80]，训练人们如何处理罕见而困难的人际关系情境 [44, 52, 94]，验证社会科学理论 [12, 46]，构建用于理论和可用性测试的模型人类处理器 [23, 39, 51]，支持普适计算应用 [31] 和社交机器人 [10, 14]，并支撑可导航复杂人际关系的非玩家游戏角色 [59, 85] 。</p>
<p>然而，人类行为的领域广阔而复杂 [85, 108]。尽管在能够在单个时间点上模拟人类行为的大型语言模型方面取得了显著进展 [18]，保证长期一致性的完全通用代理更适合采用管理不断增长的记忆的架构，以应对新的互动、冲突和事件的出现和消逝，同时处理在多个代理之间展开的级联社会动态。成功需要一种能够在长时间内检索相关事件和互动，反思这些记忆以进行概括和得出更高层次的推理，并将这种推理应用于在代理的行为中在当前和更长期的轨迹中都是合理的计划和反应的方法。</p>
<p>在本文中，我们介绍生成式代理——利用生成模型模拟可信人类行为的代理，并证明它们产生了个体和紧急组群行为的可信模拟。生成式代理对自身、其他代理和环境进行多样化的推理；它们制定反映其特征和经验的日常计划，执行这些计划，在适当时进行反应和重新规划；当最终用户改变他们的环境或用自然语言指令它们时，它们能够作出响应。例如，生成式代理会在看到早餐烧焦时关闭炉子，在浴室被占用时等在外面等待，并在遇到希望交谈的其他代理时停下来聊天。一个充满生成式代理的社会会出现新的社会动态，新的关系形成，信息扩散，代理之间协调产生。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>INTRODUCTION Part-2</h1>
<p>To enable generative agents, we describe an agent architecture that stores, synthesizes, and applies relevant memories to generate believable behavior using a large language model. Our architecture comprises three main components. The first is the memory stream, a long-term memory module that records, in natural language, a comprehensive list of the agent's experiences. A memory retrieval model combines relevance, recency, and importance to surface the records needed to inform the agent's moment-to-moment behavior. The second is reflection, which synthesizes memories into higherlevel inferences over time, enabling the agent to draw conclusions about itself and others to better guide its behavior. The third is planning, which translates those conclusions and the current environment into high-level action plans and then recursively into detailed behaviors for action and reaction. These reflections and plans are fed back into the memory stream to influence the agent's future behavior.
This architecture suggests applications in multiple domains, from role-play and social prototyping to virtual worlds and games. In social role-play scenarios (e.g., interview preparation), a user could safely rehearse difficult, conflict-laden conversations. When prototyping social platforms, a designer could go beyond temporary personas to prototype dynamic, complex interactions that unfold over time. For this paper, we focus on the ability to create a small, interactive society of agents inspired by games such as The Sims. 2By connecting our architecture to the ChatGPT large language model [77], we manifest a society of twenty-five agents in a game environment. End users can observe and interact with these agents. If an end user or developer wanted the town to host an in-game Valentine's Day party, for example, traditional game environments would require scripting tens of characters' behavior manually. We demonstrate that, with generative agents, it is sufficient to simply tell one agent that she wants to throw a party. Despite many potential points of failure-the party planner must remember to invite other agents to the party, attendees must remember the invitation, those who remember must decide to actually show up, and moreour agents succeed. They spread the word about the party and then show up, with one agent even asking another on a date to the party, all from a single user-generated seed suggestion.
We conducted two evaluations of generative agents: a controlled evaluation to test whether the agents produce believable individual behaviors in isolation, and an end-to-end evaluation where the agents interacted with each other in open-ended ways over two days of game time to understand their stability and emergent social behaviors. In the technical evaluation, we leverage a methodological opportunity to evaluate an agent's knowledge and behavior by "interviewing" it in natural language to probe the agents' ability to stay in character, remember, plan, react, and reflect accurately. We compared several ablations that limit agents' access to memory, reflection, and planning. We observe that each of these components is critical to strong performance across these interview tasks. Across the technical and end-to-end evaluation, the most common errors arose when the agent failed to retrieve relevant memories, fabricated embellishments to the agent's memory, or inherited overly formal speech or behavior from the language model.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>为了实现生成型代理（generative agents），我们描述了一个代理体系结构，它通过使用大型语言模型存储、综合和应用相关的记忆来生成可信的行为。我们的体系结构包括三个主要组件。第一个是记忆流（memory stream），它是一个长期记忆模块，用自然语言记录代理的经历的全面列表。记忆检索模型结合了相关性、新鲜度和重要性，以提取出需要支持代理的时刻行为的记录。第二个组件是反思（reflection），它将记忆合成为随着时间推移的高级推理，使代理能够对自身和他人进行推断，以更好地指导行为。第三个组件是规划（planning），它将这些推断和当前环境转化为高级行动计划，然后递归地转化为详细的行动和反应。这些反思和计划被反馈回记忆流，以影响代理的未来行为。</p>
<p>这个体系结构在多个领域都有应用，从角色扮演和社交原型设计到虚拟世界和游戏。在社交角色扮演场景中（例如，面试准备），用户可以安全地排练困难、充满冲突的对话。在原型设计社交平台时，设计师可以超越临时角色，原型设计随时间展开的动态、复杂的互动。在本文中，我们专注于创建一个受到《模拟人生》等游戏启发的小型互动代理社区的能力。通过将我们的体系结构连接到ChatGPT大型语言模型，我们在游戏环境中构建了一个由25个代理组成的社会。最终用户可以观察和与这些代理进行互动。例如，如果最终用户或开发者希望在游戏中的小镇举办情人节派对，传统的游戏环境通常需要手动编写数十个角色的行为脚本。我们证明，通过生成型代理，只需告诉一个代理她想举办派对就足够了。尽管存在许多潜在的失败点-派对策划者必须记住邀请其他代理参加派对，接收邀请的人必须记得邀请，那些记得邀请的人必须决定真的出席等等-但我们的代理成功地完成了任务。她们传播了派对的消息，然后出席了派对，其中一个代理甚至邀请另一个代理一起参加派对，所有这些都来自一个用户提供的种子建议。</p>
<p>我们进行了两项评估：一项对控制变量进行的评估，测试代理在独立情境下是否产生可信的个体行为；另一项是对代理进行的端到端评估，代理在两天的游戏时间内以开放性方式相互作用，以了解其稳定性和新兴的社会行为。在技术评估中，我们利用机会对代理进行“面试”来评估其知识和行为能力，以探究代理在角色扮演、记忆、规划、反应和反思等方面的准确性。我们比较了几个消融实验，限制了代理对记忆、反思和规划的访问。我们观察到，这些组件在面试任务中的良好表现至关重要。在技术和端到端评估中，最常见的错误出现在代理无法检索到相关记忆时，为代理的记忆进行虚构修饰，或者从语言模型中继承过于正式的语言和行为。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>INTRODUCTION Part-3</h1>
<p>In sum, this paper makes the following contributions:
• Generative agents, believable simulacra of human behavior that are dynamically conditioned on agents' changing experiences and environment. • A novel architecture that makes it possible for generative agents to remember, retrieve, reflect, interact with other agents, and plan through dynamically evolving circumstances.
The architecture leverages the powerful prompting capabilities of large language models and supplements those capabilities to support longer-term agent coherence, the ability to manage dynamically evolving memory, and recursively produce higher-level reflections. • Two evaluations, a controlled evaluation and an end-to-end evaluation, that establish causal effects of the importance of components of the architecture, as well as identify breakdowns arising from, e.g., improper memory retrieval. • Discussion of the opportunities and ethical and societal risks of generative agents in interactive systems. We argue that these agents should be tuned to mitigate the risk of users forming parasocial relationships, logged to mitigate risks stemming from deepfakes and tailored persuasion, and applied in ways that complement rather than replace human stakeholders in design processes.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>总结起来，本文提出了以下贡献：
• 生成型智能体，即可信的人类行为模拟，其动态地受到智能体不断变化的经验和环境的制约。
• 一种创新的架构，使生成型智能体能够记忆、检索、反思、与其他智能体互动，并通过不断变化的环境进行计划。
该架构充分利用了大型语言模型的强大提示能力，并补充了这些能力以支持长期智能体的连贯性、管理动态演化的记忆能力，并递归地产生更高层次的反思。</p>
<p>• 两个评估，即受控评估和端到端评估，旨在确定架构组成部分的因果效应，以及识别由于不正确的记忆检索等原因而引起的故障。
• 讨论生成型智能体在交互系统中的机会、道德和社会风险。我们认为，这些智能体应该经过调整，以减轻用户形成虚拟社交关系的风险，并进行记录以减轻由深度伪造和定制劝导产生的风险，并在不取代人类设计参与者的情况下应用于设计过程中的方式。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>RELATED WORK</h1>
<p>In this section, we reflect on the prior literature in human-AI interaction and situate, within its canon, the agenda of building believable proxies of human behavior. This agenda, once hailed as a north star in the interaction, game, and artificial intelligence communities [10,59,85,86], has remained challenging due to the complexity of human behavior [17,108]. We synthesize this research to suggest that large language models, though not sufficient by themselves, open up a new angle for creating believable agents when leveraged using the appropriate architecture.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>相关研究</p>
<p>在这一部分，我们回顾了人工智能与人类交互的先前文献，并将建立可信行为代理的议程置于其中。这个议程曾被互动、游戏和人工智能社区所赞扬[10,59,85,86]，但由于人类行为的复杂性 [17,108]，这一目标一直存在挑战。我们通过综合这方面的研究，提出了一种新的角度，即当结合适当的架构利用大型语言模型时，可以创造出可信的代理。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Human-AI Interaction</h1>
<p>Interactive artificial intelligence systems aim to combine human insights and capabilities in computational artifacts that can augment their users [4,30]. A long line of work has explored ways to enable users to interactively specify model behavior. For instance, Crayons demonstrated an early vision of interactive machine learning, allowing non-expert users to train classifiers [30]. Further work helped to articulate how end users might describe their classification goals to the system through examples [34] or demonstration [32]. Recent advancements have extended these explorations to deep learning [63] and prompt-based authoring [50,67,106]. Meanwhile, a persistent thread of research has advanced the case for language-and agent-based interaction in human-computer interaction. Formative work such as SHRDLU [103] and ELIZA [102] demonstrated the opportunities and the risks associated with natural language interaction with computing systems. As research progressed, it became evident that autonomous agents could offer new metaphors for delegation and interaction [68], but the boundaries of delegation between humans and agents have remained the subject of ongoing debate and refinement [47,89,90]. Recently, this technology has reached a level of stability that enables agents to interact via natural language in large and complex online social environments (e.g., [55]). Natural language interaction provides a novel modality that can enhance user abilities in domains such as photo editing [3,35,65] and code editing [88].
We convene these threads of work to show that we can now create agents that proxy human behavior for interactive systems, and interact with them using natural language. In doing so, this work reopens the door to examining foundational human-computer interaction questions around cognitive models such as GOMS and Keystroke-Level Model (KLM) [22,23], around prototyping tools [80], and around ubiquitous computing applications [26,31,101].</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>人工智能与人类互动系统旨在将人类的洞察和能力结合到计算工具中，以增强用户的能力[4,30]。大量的工作已经探索了各种方法，使用户能够交互式地指定模型行为。例如，Crayons展示了交互式机器学习的早期视觉，允许非专业用户训练分类器[30]。进一步的工作帮助明确了最终用户如何通过示例[34]或演示[32]来描述他们的分类目标给系统。最近的进展将这些研究拓展到了深度学习[63]和基于提示的创作[50,67,106]。与此同时，持续的研究已经提升了人机交互中的语言和智能体交互的地位。SHRDLU[103]和ELIZA[102]等开创性的工作展示了通过自然语言与计算系统交互的机会和风险。随着研究的进展，人们意识到自治体可以为委派和交互提供新的隐喻[68]，但人类和智能体之间的委托界限仍然是持续的辩论和完善的对象[47,89,90]。最近，这项技术已经达到了稳定的水平，使智能体能够在大型复杂的在线社交环境中通过自然语言进行交互（例如[55]）。自然语言交互提供了一种新颖的模态，可以增强用户在诸如照片编辑[3,35,65]和代码编辑[88]等领域的能力。
我们汇集这些工作的线索以展示我们现在可以创建代理人来模拟人类行为，用自然语言与其互动。通过这样做，本研究重新探讨了关于认知模型（如GOMS和Keystroke-Level Model (KLM)）[22,23]、原型工具[80]和普适计算应用[26,31,101]等基础性人机交互问题。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Believable Proxies of Human Behavior</h1>
<p>Prior literature has described believability, or believable agents, as a central design and engineering goal. Believable agents are designed to provide an illusion of life and present a facade of realism in the way they appear to make decisions and act on their own volition, similar to the characters in Disney movies [10,96]. These agents can populate and perceive an open world environment like the one we inhabit [10,59], and strive to behave in ways that exhibit emergent behaviors grounded in social interactions with users or other agents with the aim of becoming believable proxies of our behavior in hypothetical simulations of individuals and communities [20,36,71]. Historically, these agents were developed in the context of intelligent game non-player characters (NPCs) [59,85]. Creating NPCs with believable behavior, if possible, could enhance player experiences in games and interactive fictions by enabling emergent narratives [8,16,49,93] and social interactions with the agents [109]. However, more importantly, game worlds provide increasingly realistic representations of real-world affordances, and as observed by Laird and van Lent in 2001, these simulated worlds offer accessible testbeds for developers of believable agents to finesse the agents' cognitive capabilities without worrying about implementing robotics in the real world or creating simulation environments from scratch [59,85].
A diverse set of approaches to creating believable agents emerged over the past four decades. In implementation, however, these approaches often simplified the environment or dimensions of agent behavior to make the effort more manageable [17,73]. Rule-based approaches, such as finite-state machines [91,97] and behavior trees [41,54,82] account for the brute force approach of humanauthoring the agent's behavior [71]. They provide a straightforward way of creating simple agents that is still the most dominant approach today [69,74,108], and can even handle rudimentary social interactions, as shown in games such as Mass Effect [13] and The Sims [7] series. Nonetheless, manually crafting behavior that can comprehensively address the breadth of possible interactions in an open world is untenable. This means that the resulting agent behaviors may not fully represent the consequences of their interactions [70][71][72], and cannot perform new procedures that were not hard-coded in their script [91,97]. On the other hand, prevalent learning-based approaches for creating believable agents, such as reinforcement learning, have overcome the challenge of manual authoring by letting the agents learn their behavior, and have achieved superhuman performance in recent years in games such as AlphaStar for Starcraft [99] and OpenAI Five for Dota 2 [11]. However, their success has largely taken place in adversarial games with readily definable rewards that a learning algorithm can optimize for. They have not yet addressed the challenge of creating believable agents in an open world [40,74,91].
Cognitive architectures in computation, pioneered by Newell, aimed to build the infrastructure for supporting a comprehensive set of cognitive functions [76] that suited the all-encompassing nature of believable agents held in its original vision. They fueled some of the earliest examples of believable agents. For instance, Quakebot-SOAR [60] and ICARUS [25,64] generated NPCs in firstperson shooter games, while TacAir-SOAR [81] generated pilots in aerial combat training simulations. The architectures used by these agents differed (Quakebot-and TacAir-SOAR relied on SOAR [61], while ICARUS relied on its own variation that was inspired by SOAR and ACT-R [6]), but they shared the same underlying principle [62]. They maintained short-term and long-term memories, filled these memories with symbolic structures, and operated in perceive-plan-act cycles, dynamically perceiving the environment and matching it with one of the manually crafted action procedures [58,97]. Agents created using cognitive architectures aimed to be generalizable to most, if not all, open world contexts and exhibited robust behavior for their time. However, their space of action was limited to manually crafted procedural knowledge, and they did not offer a mechanism through which the agents could be inspired to seek new behavior. As such, these agents were deployed mostly in non-open world contexts such as first-person shooter games [25,60] or blocks worlds [64].
Today, creating believable agents as described in its original definition remains an open problem [85,108]. Many have moved on, arguing that although current approaches for creating believable agents might be cumbersome and limited, they are good enough to support existing gameplay and interactions [24,75,108]. Our argument is that large language models offer an opportunity to re-examine these questions, provided that we can craft an effective architecture to synthesize memories into believable behavior. We offer a step toward such an architecture in this paper.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>可信代理人：人类行为的交互模拟形象</p>
<p>先前的文献已经描述了可信度或可信代理人作为设计和工程目标的核心。可信代理人的设计旨在提供一种生命的幻象，并以它们自主决策和行动的方式呈现出逼真的外观，类似于迪士尼电影中的角色。这些代理人可以在我们所居住的开放世界环境中创建和感知，并努力以展示出与用户或其他代理人的社交互动有关的新兴行为为目标，成为我们行为的可信代理人在个体和社群的假设模拟中。从历史上看，这些代理人是在智能游戏中非玩家角色（NPC）的背景下开发的。如果可能创建具有可信行为的NPC，可以通过启用新兴的叙事和与代理人的社交互动来提升玩家在游戏和互动故事中的体验。然而，更重要的是，游戏世界提供了对真实世界条件的越来越逼真的描述，并且正如Laird和van Lent在2001年观察到的那样，这些模拟世界为具有可信行为的代理人的开发者提供了可访问的试验平台，以优化代理人的认知能力，而无需担心在现实世界中实施机器人技术或单独创建模拟环境。</p>
<p>在过去的四十年里，出现了一系列不同的方法来创建可信代理人。然而，在实施过程中，这些方法通常简化了环境或代理人行为的维度，以使努力更加可管理。基于规则的方法，如有限状态机和行为树，考虑到了人工撰写代理人行为的暴力方法。它们提供了一种简单的创建简单代理人的方法，至今仍然是最主要的方法，并且甚至可以处理基本的社交互动，就像在Mass Effect和The Sims等游戏中显示的那样。然而，手工构建可以全面应对开放世界可能互动广度的行为是不可行的。这意味着产生的代理人行为可能无法完全代表它们的互动后果，并且无法执行未在其脚本中硬编码的新程序。另一方面，用于创建可信代理人的主要基于学习的方法，如强化学习，通过让代理人学习其行为来解决手工创作的挑战，并且近年来在像Starcraft的AlphaStar和Dota 2的OpenAI Five这样的游戏中取得了超人类水平的表现。然而，它们的成功主要发生在具有明确定义奖励的对抗性游戏中，学习算法可以对其进行优化。它们尚未解决在开放世界中创建可信代理人的挑战。</p>
<p>计算中的认知架构，由Newell开创，旨在构建支持一套全面的认知功能的基础设施，以适应可信代理人的全方位特性。它们促成了一些最早的可信代理人的例子。例如，Quakebot-SOAR和ICARUS在第一人称射击游戏中生成NPC，而TacAir-SOAR则在空中作战训练模拟中生成飞行员。这些代理人使用的架构不同（Quakebot和TacAir-SOAR依赖于SOAR，而ICARUS依赖于受SOAR和ACT-R启发的自身变体），但它们共享相同的基本原则。它们维护短期和长期记忆，用符号结构填充这些记忆，并通过感知-规划-行动循环进行操作，动态地感知环境并将其匹配到手工创建的行动过程之一。使用认知架构创建的代理人旨在普遍适用于大多数，如果不是所有的开放世界情境，并展示了当时的强大行为。然而，它们的行动空间仅限于手工创建的程序化知识，并且它们没有提供一个机制，可以激发代理人寻求新的行为。因此，这些代理人主要部署在非开放世界情境，如第一人称射击游戏或方块世界中。</p>
<p>如今，根据其原始定义创建可信代理人仍然是一个开放性问题。许多人已经放弃，认为尽管当前用于创建可信代理人的方法可能繁琐和有限，但它们已足以支持现有的游戏玩法和互动。我们的论点是，大规模语言模型为重新审视这些问题提供了机会，前提是我们能够构建一种有效的架构来将记忆合成为可信行为。在本文中，我们提供了朝着这种架构的一步。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Large Language Models and Human Behavior</h1>
<p>Generative agents leverage a large language model to power their behavior. The key observation is that large language models encode a wide range of human behavior from their training data [15,18]. If prompted with a narrowly defined context, the models can be used to generate believable behavior. Recent work has demonstrated the efficacy of this approach. For instance, social simulacra used a large language model to generate users that would populate new social computing systems to prototype their emergent social dynamics [80]. This approach used a prompt chain [105,106] to generate short natural language descriptions of personas and their behaviors as they appear in the system being prototyped. Other empirical studies have replicated existing social science studies [46], political surveys [92], and generated synthetic data [39]. Large language models have also been used to generate interactive human behavior for users to engage with. In gaming, for instance, these models have been employed to create interactive fiction [37] and text adventure games [21]. With their ability to generate and decompose action sequences, large language models have also been used in planning robotics tasks [48]. For example, when presented with a task, such as picking up a bottle, the model is prompted to break down the task into smaller action sequences, such as heading to the table where the bottle is located and picking it up. We posit that, based on the work summarized above, large language models can become a key ingredient for creating believable agents. The existing literature largely relies on what could be considered first-order templates that employ few-shot prompts [38,66] or chain-of-thought prompts [100]. These templates are effective in generating behavior that is conditioned solely on the agent's current environment (e.g., how would a troll respond to a given post, what actions would a robot need to take to enter a room given that there is a door). However, believable agents require conditioning not only on their current environment but also on a vast amount of past experience, which is a poor fit (and as of today, impossible due to the underlying models' limited context window) using first-order prompting. Recent studies have attempted to go beyond first-order prompting by augmenting language models with a static knowledge base and an information retrieval scheme [53] or with a simple summarization scheme [104]. This paper extends these ideas to craft an agent architecture that handles retrieval where past experience is dynamically updated at each time step and mixed with agents' current context and plans, which may either reinforce or contradict each other.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>大语言模型和人类行为</p>
<p>生成型代理利用大语言模型来驱动它们的行为。关键观察是大语言模型从它们的训练数据中编码了广泛的人类行为范围[15,18]。如果给定一个狭义的上下文，这些模型可以用来生成可信的行为。最近的研究已经证明了这种方法的有效性。例如，社交模拟使用了一个大语言模型来生成用户，这些用户将填充新的社交计算系统以原型化其新兴社交动态[80]。这种方法使用了一个提示链[105,106]来生成在被原型化的系统中出现的角色和行为的短的自然语言描述。其他经验研究也重复了现有的社会科学研究[46]、政治调查[92]和生成合成数据[39]。大语言模型还被用来生成用户可以交互的人类行为。例如，在游戏中，这些模型被用来创建互动小说[37]和文本冒险游戏[21]。由于它们能够生成和分解行动序列，大语言模型还被用于计划机器人任务[48]。例如，当提供给模型一个任务，比如拿起一个瓶子，模型会被提示将任务分解成更小的行动序列，比如前往放置瓶子的桌子上并将其拿起。我们认为，基于上面总结的工作，大语言模型可以成为创建可信代理的一个关键组成部分。现有的文献主要依赖于可以被视为一阶模板的方法，这些模板使用了少样本提示[38,66]或思维链提示[100]。这些模板可以生成仅基于代理当前环境的行为（例如，一个巨魔如何回应给定的帖子，一个机器人需要采取哪些行动才能进入一个房间，假设有一扇门）。然而，可信代理不仅需要对其当前环境进行条件编码，还需要对大量的过去经验进行条件编码，而这在使用一阶提示时是很困难的（甚至可以说是不可能的，因为基础模型的上下文窗口限制）。最近的研究试图超越一阶提示，通过在语言模型中增加静态知识库和信息检索方案[53]或简单的摘要方案[104]。本文将这些思想推广到了一个代理架构中，该架构处理检索，在每个时间步骤中动态更新过去的经验，并将其与代理的当前环境和计划混合，这些计划可能会相互加强或矛盾。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>GENERATIVE AGENT BEHAVIOR AND INTERACTION</h1>
<p>To illustrate the affordances of generative agents, we instantiate them as characters in a simple sandbox world reminiscent of The Sims [7]. This sprite-based sandbox game world, Smallville, evokes a small town environment. In this section, we will walk through the affordances and interactions with generative agents in Smallville and describe how the agents behave within it. Then, in Section 4, we will introduce our generative agent architecture that powers these affordances and interactions. In Section 5, we will describe the The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas (e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agents remember a subgraph that reflects the parts of the world they have seen, maintaining the state of those parts as they observed them.
implementation of the sandbox environment and how the agents interact with the underlying engine of the sandbox world.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>为了展示生成型代理的优点，我们将它们实例化为一个简单的模拟沙盒世界中的角色，类似于《模拟人生》[7]。这个基于精灵的沙盒游戏世界，Smallville，呈现一个小镇环境。在本章中，我们将介绍在Smallville中与生成型代理的作用和互动，以及它们在其中的行为方式。然后，在第四章中，我们将介绍驱动这些作用和互动的生成型代理架构。在第五章中，我们将描述The Smallville沙盒世界，并标注出不同的区域。根节点描述整个世界，子节点描述区域（如房屋、咖啡厅、商店），叶节点描述物体（如桌子、书架）。代理记住一个子图，反映他们所见过的世界的不同部分，并维护这些部分的状态随着他们的观察而改变。
实现沙盒环境以及代理与沙盒世界的底层引擎的交互。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Agent Avatar and Communication</h1>
<p>A community of 25 unique agents inhabits Smallville. Each agent is represented by a simple sprite avatar. We authored one paragraph of natural language description to depict each agent's identity, including their occupation and relationship with other agents, as seed memories. For example, John Lin has the following description:
John Lin is a pharmacy shopkeeper at the Willow Market and Pharmacy who loves to help people. He is always looking for ways to make the process of getting medication easier for his customers; John Lin is living with his wife, Mei Lin, who is a college professor, and son, Eddy Lin, who is a student studying music theory; John Lin loves his family very much; John Lin has known the old couple next-door, Sam Moore and Jennifer Moore, for a few years; John Lin thinks Sam Moore is a kind and nice man; John Lin knows his neighbor, Yuriko Yamamoto, well; John Lin knows of his neighbors, Tamara Taylor and Carmen Ortiz, but has not met them before; John Lin and Tom Moreno are colleagues at The Willows Market and Pharmacy; John Lin and Tom Moreno are friends and like to discuss local politics together; John Lin knows the Moreno family somewhat well -the husband Tom Moreno and the wife Jane Moreno.
Each semicolon-delimited phrase is entered into the agent's initial memory as memories at the start of the simulation.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>代理头像与通信</p>
<p>Smallville中有一个由25个独特代理组成的社区。每个代理都由简单的精灵头像来表示。我们编写了一个自然语言描述段落来描绘每个代理的身份，包括他们的职业和与其他代理的关系，作为种子记忆。例如，John Lin具有以下描述：
John Lin是Willow市场和药店的一位药店店主，他热衷于帮助人们。他一直在寻找让顾客更容易获得药物的方法；John Lin与他的妻子Mei Lin和儿子Eddy Lin一起生活，Mei Lin是一名大学教授，Eddy Lin是一名研究音乐理论的学生；John Lin非常爱他的家人；John Lin认识隔壁的老夫妇Sam Moore和Jennifer Moore已经几年了；John Lin认为Sam Moore是个友善和善良的人；John Lin很了解他的邻居Yuriko Yamamoto；John Lin对他的邻居Tamara Taylor和Carmen Ortiz有所了解，但之前没有见过他们；John Lin和Tom Moreno是Willows市场和药店的同事；John Lin和Tom Moreno是朋友，喜欢一起讨论当地政治；John Lin对Moreno一家的了解还算不错——丈夫Tom Moreno和妻子Jane Moreno。
每个以分号分隔的短语都被输入到代理在模拟开始时的初始记忆中。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Inter-Agent Communication.</h1>
<p>The agents interact with the world by their actions, and with each other through natural language. At each time step of the sandbox engine, the agents output a natural language statement describing their current action, such as "Isabella Rodriguez is writing in her journal", "Isabella Rodriguez is checking her emails", "Isabella Rodriguez is talking with her family on the phone", or "Isabella Rodriguez is getting ready for bed. " This statement is then translated into concrete movements that affect the sandbox world. The action is displayed on the sandbox interface as a set of emojis, providing an abstract representation of the action from an overhead view. To achieve this, the system utilizes a language model to translate the action into a set of emojis, which appear above each avatar's head in a speech bubble. For example, "Isabella Rodriguez is writing in her journal" is displayed as , while "Isabella Rodriguez is checking her emails" appears as . The complete natural language description of the action can be accessed by clicking on the agent's avatar.
Agents communicate with each other in full natural language. They are aware of other agents in their local area, and the generative agent architecture determines whether they walk by or engage in conversation. Here, a sample in the middle of a conversation between the agents Isabella Rodriguez and Tom Moreno about the upcoming election:3 Isabella: I'm still weighing my options, but I've been discussing the election with Sam Moore. What are your thoughts on him? Tom: To be honest, I don't like Sam Moore. I think he's out of touch with the community and doesn't have our best interests at heart.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>章节：Inter-Agent Communication</p>
<p>代理（agents）通过行动与世界互动，并通过自然语言与彼此交流。在沙盒引擎的每个时间步骤中，代理输出一条自然语言语句来描述他们当前的行动，例如“Isabella Rodriguez 正在写她的日记”，“Isabella Rodriguez 正在查看她的邮件”，“Isabella Rodriguez 正在与她的家人通电话”，或者“Isabella Rodriguez 正在准备睡觉”。然后，这条语句被转化为影响沙盒世界的具体动作。这个动作以一组表情符号的形式显示在沙盒界面上，以俯视视角抽象地表示动作。为了实现这一点，系统利用语言模型将动作转化为一组表情符号，这些表情符号会出现在每个角色头顶的说话气泡中。例如，“Isabella Rodriguez 正在写她的日记”会显示为📔，而“Isabella Rodriguez 正在查看她的邮件”则显示为📧。点击角色头像可以获取完整的自然语言描述。</p>
<p>代理之间通过完整的自然语言进行交流。他们意识到他们周围的其他代理，并由生成代理架构决定是走过去还是进行对话。下面是代理 Isabella Rodriguez 和 Tom Moreno 关于即将到来的选举进行对话的中段示例：</p>
<p>Isabella: 我还在权衡各种选择，但我一直在与 Sam Moore 讨论选举。你对他的看法如何？</p>
<p>Tom: 说实话，我不喜欢 Sam Moore。我认为他与社区脱节，不关心我们的最大利益。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>User Controls.</h1>
<p>The user communicates with the agent through natural language by specifying a persona that the agent should perceive them as. For example, if the user specifies that they are a news "reporter" and asks about the upcoming election by saying, "Who is running for office?", the John agent replies:
John: My friends Yuriko, Tom and I have been talking about the upcoming election and discussing the candidate Sam Moore. We have all agreed to vote for him because we like his platform.
To directly command one of the agents, the user takes on the persona of the agent's "inner voice"-this makes the agent more likely to treat the statement as a directive. For instance, when told "You are going to run against Sam in the upcoming election" by a user as John's inner voice, John decides to run in the election and shares his candidacy with his wife and son.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>用户通过自然语言与代理进行交流，通过指定一个代理所能感知到的人物角色与其进行交互。例如，如果用户指定自己是一个新闻"记者"，并询问即将举行的选举时说："谁参加了选举？"，约翰代理会回答：
约翰：我和我的朋友Yuriko、Tom一直在讨论即将举行的选举，并讨论候选人萨姆·摩尔。我们都决定支持他，因为我们喜欢他的政纲。
如果用户以代理的"内心声音"的角色直接命令其中一位代理，这将使代理更有可能将该陈述视为指令。例如，当用户以约翰的内心声音告诉他"你将在即将举行的选举中与萨姆竞选"时，约翰决定参选，并与他的妻子和儿子分享了自己的候选身份。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Environmental Interaction</h1>
<p>Smallville features the common affordances of a small village, including a cafe, bar, park, school, dorm, houses, and stores. It also defines subareas and objects that make those spaces functional, such as a kitchen in a house and a stove in the kitchen (Figure 2). All spaces serving as agents' primary living quarters feature a bed, desk, closet, shelf, as well as a bathroom and a kitchen. 4Agents move around Smallville as one would in a simple video game, entering and leaving buildings, navigating its map, and approaching other agents. Agent movements are directed by the generative agent architecture and the sandbox game engine: when the model dictates that the agent will move to a location, we calculate a walking path to the destination in the Smallville environment, and the agent begins moving. In addition, users can also enter the sandbox world of Smallville as an agent operating within it. The agent that the user embodies can be an agent already present in the world, such as Isabella and John, or it can be an outside visitor with no prior history in Smallville. The inhabitants of Smallville will treat the user-controlled agent no differently than they treat each other. They recognize its presence, initiate interactions, and remember its behavior before forming opinions about it.
Users and agents can influence the state of the objects in this world, much like in sandbox games such as The Sims. For example, a bed can be occupied when an agent is sleeping, and a refrigerator can be empty when an agent uses up the ingredients to make breakfast. End users can also reshape an agent's environment in Smallville by rewriting the status of objects surrounding the agent in natural language. For instance, when Isabella is making breakfast in the morning, the user can change the status of the kitchen stove from "turned on" to "burning" by inputting a command to the system that chooses the object and illustrates its new status, like this: "<Isabella's apartment: kitchen: stove> is burning." Isabella will notice this in the next moment and go to turn off the stove and remake her breakfast. Likewise, if the user sets the status of Isabella's shower to "leaking water" when she enters the bathroom, she will gather tools from her living room and try to fix the leak.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>小镇拥有一个小村庄常见的设施，包括咖啡馆、酒吧、公园、学校、宿舍、房子和商店等。它还定义了一些次区域和对象，使这些空间具备功能，例如房子里的厨房和厨房里的炉灶（图2）。所有作为居住地的空间都配备有床、书桌、衣柜、架子，以及浴室和厨房。代理人在Smallville中的移动方式类似于简单的视频游戏，进入和离开建筑物，导航地图，并接近其他代理人。代理人的移动由生成代理架构和沙盒游戏引擎控制：当模型决定代理人将移动到一个位置时，我们会计算到达Smallville环境的目标位置的行走路径，然后代理人开始移动。此外，用户还可以作为一个代理人进入Smallville的沙盒世界进行操作。用户所扮演的代理人可以是已经存在于世界中的代理人，如Isabella和John，或者是没有在Smallville中有过历史的外来访客。Smallville的居民们对用户所控制的代理人没有任何差别对待。他们会意识到代理人的存在，主动发起互动，并在形成对其意见之前记住代理人的行为。</p>
<p>用户和代理人可以像《模拟人生》等沙盒游戏中那样影响这个世界中的物体状态。例如，当代理人睡觉时，床被占用，当代理人用完食材做早餐时，冰箱会变空。最终用户还可以通过以自然语言重写代理人环境中周围物体的状态来改变Smallville中的环境。例如，当Isabella早上准备早餐时，用户可以输入一个命令将厨房炉灶的状态从“打开”改为“着火”，并选择对象并说明其新的状态，例如：<Isabella的公寓：厨房：炉灶>着火。Isabella下一刻会注意到这一点，赶紧去关掉炉灶并重新做早餐。同样，如果用户将Isabella的淋浴间状态设置为“漏水”当她进入浴室时，她会从客厅拿起工具来修理漏水问题。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Example "Day in the Life"</h1>
<p>Starting from the single-paragraph description, generative agents begin planning their days. As time passes in the sandbox world, their behaviors evolve as these agents interact with each other and the world, building memories and relationships, and coordinating joint activities.
We demonstrate the behavior of generative agents by tracing the output of our system over the course of one day for the agent John Lin (Figure 3). In the Lin family, John is the first to wake up at 7 a.m. He brushes his teeth, takes a shower, gets dressed, eats breakfast, and checks the news at the dining table in the living room. At 8 a.m., Eddy follows suit, rushing out of bed to prepare for his classes. He catches up with John just as he is about to head out:
John: Good morning Eddy. Did you sleep well? Eddy: Good morning dad. Yeah, I slept great. John: That's good. What are you working on today? Eddy: I'm working on a new music composition for my class. It's due this week, so I'm trying to get it finished. But I'm having so much fun with it! John: That sounds great! Soon after Eddy heads out, Mei wakes up and joins John. Mei asks about her son, and John recalls the conversation they just had:
Mei: Did Eddy already leave for school? John: Yes, he just left. He's working on a music composition for his class. Mei: Oh, that's wonderful! Tell me about it. John: I think he's really enjoying it! He said he's having a lot of fun with it. Mei: That's great! I'm so proud of him.
As they finish their conversation, Mei and John pack up. Mei goes on to teach and work on her research paper, while John opens his pharmacy counter at the Willow Market and Pharmacy by 9 a.m.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>从单段描述开始，生成人开始规划他们的一天。随着时间在沙盒世界中流逝，他们的行为会随着与其他人和环境的互动而演变，建立记忆和关系，并协调共同的活动。</p>
<p>我们通过追踪我们系统在一天中对代理人约翰·林（图3）的输出来展示生成人的行为。在林家，约翰是早上7点第一个起床的人。他刷牙、洗澡、穿衣、吃早餐，并在客厅的餐桌上查看新闻。早上8点，埃迪也起床了，他匆忙离开床准备上课。他赶上约翰正要出门的时候：</p>
<p>约翰：早上好埃迪。你睡得好吗？
埃迪：早上好爸爸。嗯，我睡得很好。
约翰：那太好了。你今天在做什么？
埃迪：我正在为我的课程作曲。这周要交作业，所以我想尽快完成。但是我觉得很有趣！
约翰：听起来很棒！
埃迪离开后不久，梅醒来并加入约翰。梅问起她的儿子，约翰回忆起他们刚刚的对话：</p>
<p>梅：埃迪已经去上学了吗？
约翰：是的，他刚刚离开。他正在为他的课程作曲。
梅：哦，那太好了！告诉我详细一点。
约翰：我觉得他真的喜欢！他说他觉得很有趣。
梅：太好了！我为他感到骄傲。</p>
<p>结束他们的对话后，梅和约翰整理好东西。梅去上课并拿出她的研究论文，而约翰在上午9点开设他的药房柜台，位于Willow超市和药店中。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Emergent Social Behaviors</h1>
<p>By interacting with each other, generative agents in Smallville exchange information, form new relationships, and coordinate joint activities. Extending prior work [80], these social behaviors are emergent rather than pre-programmed.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>在Smallville中，生成的代理通过相互交互来交换信息、建立新的关系并协调联合活动。与之前的研究[80]相比，这些社交行为是 emergent ( emergent 是指 emergent behavior，即 Emergent Behaviors的表达方式) ，而不是预先编程的。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Information Diffusion.</h1>
<p>As agents notice each other, they may engage in dialogue-as they do so, information can spread from agent to agent. For instance, in a conversation between Sam and Tom at the grocery store, Sam tells Tom about his candidacy in the local election:   Later that day, after Sam left, Tom and John, who heard the news from another source, discuss Sam's chances of winning the election:
John: I heard that Sam Moore is running for mayor in the local election. Do you think he has a good chance of winning? Tom: I do think he has a good chance. He's been working hard in the community and I think he will get a lot of support. What do you think? John: I think it's great that he's running. I'm curious to see how the election will turn out.
Gradually, Sam's candidacy becomes the talk of the town, with some supporting him and others remaining undecided.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>信息传播</p>
<p>当代理人注意到彼此时，它们可能会进行对话-在这个过程中，信息可以从一个代理人传播到另一个代理人。例如，在杂货店里，Sam和Tom之间进行了一次对话，Sam告诉Tom他参加了当地选举的候选人身份：那天晚些时候，Sam离开后，Tom和John讨论Sam在选举中获胜的可能性：</p>
<p>John：我听说Sam Moore在当地选举中竞选市长。你觉得他有很大的获胜机会吗？
Tom：我确实认为他有很大的机会。他在社区工作很努力，我认为他会得到很多支持。你觉得呢？
John：我觉得他竞选很棒。我很好奇选举结果会如何。</p>
<p>渐渐地，Sam的候选人身份成为了城里的话题，一些人支持他，而其他人则持观望态度。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Relationship Memory.</h1>
<p>Agents in Smallville form new relationships over time and remember their interactions with other agents. For example, at the start, Sam does not know Latoya Williams. While taking a walk in Johnson Park, Sam runs into Latoya, and they introduce themselves. Latoya mentions that she is working on a photography project: "I'm here to take some photos for a project I'm working on." In a later interaction, Sam's interactions with Latoya indicate a memory of that interaction, as he asks "Hi, Latoya. How is your project going?" and she replies "Hi, Sam. It's going well!" 3.4.3 Coordination. Generative agents coordinate with each other. Isabella Rodriguez, at Hobbs Cafe, is initialized with an intent to plan a Valentine's Day party from 5 to 7 p.m. on February 14th. From this seed, the agent proceeds to invite friends and customers when she sees them at Hobbs Cafe or elsewhere. Isabella then spends the afternoon of the 13th decorating the cafe for the occasion. Maria, a frequent customer and close friend of Isabella's, arrives at the cafe. Isabella asks for Maria's help in decorating for the party, and Maria agrees. Maria's character description mentions that she has a crush on Klaus. That night, Maria invites Klaus, her secret crush, to join her at the party, and he gladly accepts.
On Valentine's Day, five agents, including Klaus and Maria, show up at Hobbs Cafe at 5 pm, and they enjoy the festivities (Figure 4). In this scenario, the end user only set Isabella's initial intent to throw a party and Maria's crush on Klaus: the social behaviors of spreading the word, decorating, asking each other out, arriving at the party, and interacting with each other at the party were initiated by the agent architecture. Agents perceive their environment, and all perceptions are saved in a comprehensive record of the agent's experiences called the memory stream. Based on their perceptions, the architecture retrieves relevant memories and uses those retrieved actions to determine an action. These retrieved memories are also used to form longer-term plans and create higher-level reflections, both of which are entered into the memory stream for future use.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>第3.4.3节：协调</p>
<p>Smallville中的代理人随着时间的推移建立新的关系，并记住他们与其他代理人的互动。例如，在开始时，Sam不认识Latoya Williams。在Johnson公园散步时，Sam遇到了Latoya，他们互相介绍。Latoya提到她正在进行一个摄影项目：“我在这里拍一些照片为我正在进行的项目。”在后续的互动中，Sam与Latoya的互动表明他记得那次互动，他问道：“嗨，Latoya。你的项目进展如何？”她回答：“嗨，Sam。进行得很顺利！” </p>
<p>生成代理人相互协调。Isabella Rodriguez在Hobbs咖啡馆计划在2月14日下午5点到7点期间举办情人节派对的意图被初始化。根据这个设定，代理人会在在Hobbs咖啡馆或其他地方看到朋友和顾客时邀请他们参加。然后，Isabella在13日下午装饰咖啡馆以为派对做准备。Maria是Isabella的常客和密友，她来到咖啡馆。Isabella请求Maria帮忙装饰派对，Maria答应了。Maria的角色描述中提到她暗恋Klaus。那天晚上，Maria邀请她暗恋的Klaus一起参加派对，他欣然接受。</p>
<p>情人节那天，包括Klaus和Maria在内的五个代理人在下午5点出现在Hobbs咖啡馆，并享受派对的氛围（图4）。在这种情景中，最终用户只设定了Isabella举办派对的初始意图和Maria对Klaus的暗恋。传播消息、装饰、约会、到达派对并相互交流的社交行为是由代理人架构主导的。代理人感知他们的环境，并且所有的感知都保存在一个完整的代理人体验记录中，称为记忆流。根据他们的感知，架构检索相关的记忆，并使用这些检索到的行动来确定一个行动。这些检索到的记忆也用于制定长期计划和创建更高层次的反思，这些都会被输入到记忆流中以供将来使用。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>GENERATIVE AGENT ARCHITECTURE</h1>
<p>Generative agents aim to provide a framework for behavior in an open world: one that can engage in interactions with other agents and react to changes in the environment. Generative agents take their current environment and past experiences as input and generate behavior as output. Underlying this behavior is a novel agent architecture that combines a large language model with mechanisms for synthesizing and retrieving relevant information to condition the language model's output. Without these mechanisms, large language models can output behavior, but the resulting agents may not react based on the agent's past experiences, may not make important inferences, and may not maintain long-term coherence. Challenges with long-term planning and coherence remain [19] even with today's most performant models such as GPT-4. Because generative agents produce large streams of events and memories that must be retained, a core challenge of our architecture is to ensure that the most relevant pieces of the agent's memory are retrieved and synthesized when needed.
At the center of our architecture is the memory stream, a database that maintains a comprehensive record of an agent's experience. From the memory stream, records are retrieved as relevant to plan the agent's actions and react appropriately to the environment. Records are recursively synthesized into higher-and higher-level reflections that guide behavior. Everything in the architecture is recorded and reasoned over as a natural language description, allowing the architecture to leverage a large language model.
Our current implementation utilizes the gpt3.5-turbo version of ChatGPT [77]. We expect that the architectural basics of generative agents-memory, planning, and reflection-will likely remain the same as language models improve. Newer language models (e.g., GPT-4) will continue to expand the expressive power and performance of the prompts that underpin generative agents. As of writing, however, GPT-4's API was invitation-only, so our agents use ChatGPT.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>生成型智能体旨在为开放世界中的行为提供一个框架：能够与其他智能体进行交互，并对环境变化做出反应。生成型智能体以当前环境和过往经验作为输入，并生成行为作为输出。支持这种行为的是一种新颖的智能体架构，该架构将一个大型语言模型与合成和检索相关信息的机制相结合，以影响语言模型的输出。没有这些机制，大型语言模型可以输出行为，但是所生成的智能体可能不会基于智能体的过往经验做出反应，可能不会进行重要的推理，并且可能无法保持长期的连贯性。即使是如GPT-4这样表现最佳的模型，长期规划和连贯性仍然存在挑战[19]。由于生成型智能体产生大量的事件和记忆，这些必须被保留，我们架构的一个核心挑战是确保智能体记忆中最相关的部分在需要时可以被检索和合成。</p>
<p>在我们的架构的核心是记忆流，它是一个数据库，用于记录智能体的经验。从记忆流中，根据计划智能体的行动和对环境作出适当反应所需，进行记录检索。记录逐步合成为更高级的反思，指导行为。架构中的所有内容都以自然语言描述的形式记录和推理，以便利用大型语言模型。</p>
<p>我们目前的实现使用的是ChatGPT的gpt3.5-turbo版本[77]。我们预计，随着语言模型的改进，生成型智能体的基本架构-记忆、规划和反思-可能会保持相同。新的语言模型（如GPT-4）将继续扩展支撑生成型智能体的提示的表达能力和性能。然而，截至撰写本文时，GPT-4的API仅限邀请使用，因此我们的智能体使用ChatGPT。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Memory and Retrieval</h1>
<p>Challenge: Creating generative agents that can simulate human behavior requires reasoning about a set of experiences that is far larger than what should be described in a prompt, as the full memory stream can distract the model and does not even currently fit into the limited context window. Consider the Isabella agent answering the question, "What are you passionate about these days?" Summarizing all of Isabella's experiences to fit in the limited context window of the language model produces an uninformative response, where Isabella discusses topics such as collaborations for events and projects and cleanliness and organization in a cafe. Instead of summarizing, the memory stream described below surfaces relevant memories, resulting in a more informative and specific response that mentions Isabella's passion for making people feel welcome and included, planning events and creating an atmosphere that people can enjoy, such as the Valentine's Day party.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>挑战：创建能够模拟人类行为的生成式智能体需要对一系列经历进行推理，而这远远超出了一个简单提示所能描述的范围，因为完整的记忆流可能会分散模型的注意力，而且目前还无法完全适应有限的上下文窗口。考虑到Isabella智能体回答问题“最近你对什么充满热情？”的情况。将所有Isabella的经历总结到语言模型的有限上下文窗口中会产生一个没有信息的回答，其中Isabella讨论的主题包括为活动和项目进行合作、咖啡店的整洁和组织。与其总结，下面描述的记忆流将呈现相关记忆，从而产生更具信息性和具体的回答，提到了Isabella对让人们感到受欢迎和包容的热情，计划活动并创造人们可以享受的氛围，比如情人节派对。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Approach:</h1>
<p>The memory stream maintains a comprehensive record of the agent's experience. It is a list of memory objects, where each object contains a natural language description, a creation timestamp, and a most recent access timestamp. The most basic element of the memory stream is an observation, which is an event directly perceived by an agent. Common observations include behaviors performed by the agent themselves or behaviors that agents perceive being performed by other agents or non-agent objects. For instance, Isabella Rodriguez, who works at a coffee shop, might accrue the following observations over time: (1) Isabella Rodriguez is setting out the pastries, (2) Maria Lopez is studying for a Chemistry test while drinking coffee, (3) Isabella Rodriguez and Maria Lopez are conversing about planning a Valentine's day party at Hobbs Cafe, (4) The refrigerator is empty.
Our architecture implements a retrieval function that takes the agent's current situation as input and returns a subset of the memory stream to pass on to the language model. There are many possible implementations of a retrieval function, depending on what is important for the agent to consider when deciding how to act. The memory stream comprises a large number of observations that are relevant and irrelevant to the agent's current situation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its response to the situation.
In our context, we focus on three main components that, together, produce effective results.
Recency assigns a higher score to memory objects that were recently accessed, so that events from a moment ago or this morning are likely to remain in the agent's attentional sphere. In our implementation, we treat recency as an exponential decay function over the number of sandbox game hours since the memory was last retrieved. Our decay factor is 0.995.
Importance distinguishes mundane from core memories by assigning a higher score to memory objects that the agent believes to be important. For instance, a mundane event, such as eating breakfast in one's room, would yield a low importance score, whereas a breakup with one's significant other would yield a high score. There are many possible implementations of an importance score; we find that directly asking the language model to output an integer score is effective. The full prompt appears below:
On the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Memory: buying groceries at The Willows Market and Pharmacy Rating: <fill in> This prompt returns an integer value of 2 for "cleaning up the room" and 8 for "asking your crush out on a date. " The importance score is generated at the time the memory object is created.
Relevance assigns a higher score to memory objects that are related to the current situation. What is relevant depends on the answer to, "Relevant to what?", so we condition relevance on a query memory. If the query, for example, is that a student is discussing what to study for a chemistry test with a classmate, memory objects about their breakfast should have low relevance, whereas memory objects about the teacher and schoolwork should have high relevance. In our implementation, we use the language model to generate an embedding vector of the text description of each memory. Then, we calculate relevance as the cosine similarity between the memory's embedding vector and the query memory's embedding vector.
To calculate the final retrieval score, we normalize the recency, relevance, and importance scores to the range of [0, 1] using minmax scaling. The retrieval function scores all memories as a weighted combination of the three elements: 𝑠𝑐𝑜𝑟𝑒 = 𝛼 𝑟𝑒𝑐𝑒𝑛𝑐𝑦 • 𝑟𝑒𝑐𝑒𝑛𝑐𝑦 + 𝛼 𝑖𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 • 𝑖𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 + 𝛼 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 • 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒. In our implementation, all 𝛼s are set to 1. The top-ranked memories that fit within the language model's context window are included in the prompt.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>方法：</p>
<p>Memory Stream维护着一个代理的经历全面的记录。它是一个包含多个记忆对象的列表，每个对象包括自然语言描述、创建时间戳和最近访问时间戳。Memory Stream的最基本元素是观察，即代理直接感知到的事件。常见的观察包括代理自己执行的行为，以及代理感知到其他代理或非代理对象执行的行为。例如，Isabella Rodriguez，在一家咖啡店工作，随着时间的推移可能积累以下观察：（1）Isabella Rodriguez正在摆放糕点，（2）Maria Lopez正在喝咖啡时为化学考试学习，（3）Isabella Rodriguez和Maria Lopez正在讨论在Hobbs Cafe策划情人节派对，（4）冰箱是空的。</p>
<p>我们的架构实现了一个检索函数，将代理的当前情境作为输入，并返回一个子集的Memory Stream，以传递给语言模型。检索函数有多种可能的实现方式，具体取决于代理在决定如何行动时需要考虑什么因素。Memory Stream包含了许多与代理当前情境相关和不相关的观察。检索函数识别出这些观察中应该传递给语言模型以调整其对情境的响应的子集。</p>
<p>在我们的上下文中，我们将重点关注三个主要的组成部分，它们共同产生有效的结果。</p>
<p>最近性根据代理最近访问的时间给予Memory对象更高的评分，这样一段时间前或今天早晨发生的事件很可能仍然留在代理的注意力范围内。在我们的实现中，我们将最近性视为自上次检索Memory以来经过的沙盘游戏小时数的指数衰减函数。我们的衰减因子为0.995。</p>
<p>重要性通过给代理认为重要的记忆对象分配较高的评分来区分平凡的记忆和核心记忆。例如，吃早餐这样的平凡事件将得到较低的重要性评分，而与情侣分手则会得到较高的评分。关于重要性评分有很多可能的实现方式；我们发现直接要求语言模型输出一个整数评分是有效的。完整的提示如下：</p>
<p>在1到10的尺度上，其中1表示纯粹平凡（如刷牙，整理床铺），10表示非常重要（如一段恋情的结束，大学录取），请给以下记忆片段的可能重要性评分。记忆：在The Willows Market and Pharmacy购买杂货 评分： &lt;填写&gt;。对于“整理房间”，该提示返回整数值2，而对于“向心仪的人邀约出去”返回8。重要性评分是在记忆对象创建时生成的。</p>
<p>相关性给予与当前情境相关的记忆对象较高的评分。什么是相关性取决于对“与什么相关？”的回答，因此我们将相关性与查询记忆相互联系。例如，如果查询是一个学生正在与同学讨论化学考试应该学习什么，那么关于他们早餐的记忆对象应该具有较低的相关性，而关于教师和学校工作的记忆对象应该具有较高的相关性。在我们的实现中，我们使用语言模型生成每个记忆的文本描述的嵌入向量。然后，我们通过计算记忆的嵌入向量与查询记忆的嵌入向量之间的余弦相似度来计算相关性。</p>
<p>为了计算最终的检索评分，我们使用最小最大缩放将最近性、相关性和重要性评分标准化到[0, 1]的范围内。检索函数将所有的记忆按照三个元素的加权组合进行评分： 𝑠𝑐𝑜𝑟𝑒 = 𝛼 𝑟𝑒𝑐𝑒𝑛𝑐𝑦 • 𝑟𝑒𝑐𝑒𝑛𝑐𝑦 + 𝛼 𝑖𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 • 𝑖𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 + 𝛼 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒 • 𝑟𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒。在我们的实现中，所有的𝛼都设置为1。符合语言模型上下文窗口的排名靠前的记忆被包含在提示中。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Reflection</h1>
<p>Challenge: Generative agents, when equipped with only raw observational memory, struggle to generalize or make inferences. Consider a scenario in which Klaus Mueller is asked by the user: "If you had to choose one person of those you know to spend an hour with, who would it be?" With access to only observational memory, the agent simply chooses the person with whom Klaus has had the most frequent interactions: Wolfgang, his college dorm neighbor. Unfortunately, Wolfgang and Klaus only ever see each other in passing, and do not have deep interactions. A more desirable response requires that the agent generalize from memories of Klaus spending hours on a research project to generate a higherlevel reflection that Klaus is passionate about research, and likewise recognize Maria putting in effort into her own research (albeit in a different field), enabling a reflection that they share a common interest. With the approach below, when Klaus is asked who to spend time with, Klaus chooses Maria instead of Wolfgang.
Approach: We introduce a second type of memory, which we call a reflection. Reflections are higher-level, more abstract thoughts generated by the agent. Because they are a type of memory, they are included alongside other observations when retrieval occurs. Reflections are generated periodically; in our implementation, we generate reflections when the sum of the importance scores for the latest events perceived by the agents exceeds a threshold (150 in our implementation). In practice, our agents reflected roughly two or three times a day.
The first step in reflection is for the agent to determine what to reflect on, by identifying questions that can be asked given the agent's recent experiences. We query the large language model with the 100 most recent records in the agent's memory stream (e.g., "Klaus Mueller is reading a book on gentrification", "Klaus Mueller is conversing with a librarian about his research project", "desk at the library is currently unoccupied") and prompt the language model, "Given only the information above, what are 3 most salient highlevel questions we can answer about the subjects in the statements?" The model's response generates candidate questions: for example, What topic is Klaus Mueller passionate about? and What is the relationship between Klaus Mueller and Maria Lopez? We use these generated questions as queries for retrieval, and gather relevant memories (including other reflections) for each question. Then we prompt the language model to extract insights and cite the particular records that served as evidence for the insights. The full prompt is as follows: This process generates statements such as Klaus Mueller is dedicated to his research on gentrification (because of 1, 2, 8, 15). We parse and store the statement as a reflection in the memory stream, including pointers to the memory objects that were cited.
Reflection explicitly allows the agents to reflect not only on their observations but also on other reflections: for example, the second statement about Klaus Mueller above is a reflection that Klaus previously had, not an observation from his environment. As a result, agents generate trees of reflections: the leaf nodes of the tree represent the base observations, and the non-leaf nodes represent thoughts that become more abstract and higher-level the higher up the tree they are.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>挑战：当生成性代理仅配备原始观察记忆时，很难进行概括或推断。考虑这样一个场景，用户问Klaus Mueller：“如果你必须选择一个你认识的人与之共度一个小时，你会选择谁？”只有观察记忆的代理简单地选择与Klaus有最频繁互动的人：他的大学宿舍邻居Wolfgang。不幸的是，Wolfgang和Klaus只是在经过时见面，并没有深入的交流。更理想的回答需要代理从 Klaus 投入数小时的研究项目的记忆中概括出 Klaus 热衷于研究的高层次反思，并且同时认识到 Maria 也在她自己的领域努力，从而产生出他们共同兴趣的反思。下面的方法中，当 Klaus 被问到要与谁共度时间时，Klaus 选择 Maria 而不是 Wolfgang。</p>
<p>方法：我们介绍了第二种类型的记忆，我们称之为反思。反思是代理生成的更高层次、更抽象的思考。因为它们是一种记忆类型，所以在检索时与其他观察一起被包含在内。反思定期生成；在我们的实现中，当代理感知到的最新事件的重要性分数总和超过一个阈值（在我们的实现中是150）时，我们生成反思。实际上，我们的代理每天大约会反思两三次。</p>
<p>反思的第一步是代理确定反思的对象，通过确定根据代理最近的经历可以提出的问题。我们用代理记忆流的最新的100个记录进行大型语言模型查询（例如，“Klaus Mueller正在阅读一本关于城市翻新的书”、“Klaus Mueller正在与一位图书馆员讨论他的研究项目”、“图书馆的桌子当前未被占用”），并提示语言模型：“只给出上述信息，关于这些陈述中的主体，我们能回答什么是三个最显著的高层次问题？”模型的响应会生成候选问题，例如 Klaus Mueller 对什么话题充满热情？Klaus Mueller 和 Maria Lopez 之间的关系是什么？我们将这些生成的问题作为查询用于检索，并收集与每个问题相关的记忆（包括其他反思）。然后，我们提示语言模型提取洞察力，并引用作为证据的特定记录。完整的提示如下：此过程会生成类似 Klaus Mueller 对城市翻新的研究非常专注（因为有记录1、2、8和15），我们解析并将该陈述作为反思存储在记忆流中，包括指向被引用的记忆对象的指针。</p>
<p>反思明确允许代理不仅对它们的观察进行反思，还可以对其他反思进行反思：例如，上面关于 Klaus Mueller 的第二个陈述是 Klaus 以前的一个反思，而不是来自他的环境的观察。因此，代理生成反思树：树的叶节点表示基本观察，而非叶节点表示思想，这些思想越往上越抽象、高层次。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Planning and Reacting</h1>
<p>Challenge: While a large language model can generate plausible behavior in response to situational information (e.g., [46,80]), agents need to plan over a longer time horizon to ensure that their sequence of actions is coherent and believable. If we prompt a language model with Klaus's background, describe the time, and ask what action he ought to take at the given moment, Klaus would eat lunch at 12 pm, but then again at 12:30 pm and 1 pm, despite having already eaten his lunch twice. Optimizing for believability in the moment sacrifices believability over time. To overcome this issue, planning is essential. With the approach described below, Klaus's afternoon plan is less gluttonous: he has lunch at Hobbs Cafe while reading at 12pm, works on his research paper at the school library at 1pm, and takes a break for a walk in the park at 3pm.
Approach: Plans describe a future sequence of actions for the agent, and help keep the agent's behavior consistent over time. A plan includes a location, a starting time, and a duration. For instance, Klaus Mueller, who is dedicated in his research and has an impending deadline, 5 may choose to spend his day working at his desk drafting his research paper. An entry in a plan might state, for example: for 180 minutes from 9am, February 12th, 2023, at Oak Hill College Dorm: Klaus Mueller's room: desk, read and take notes for research paper. Like reflections, plans are stored in the memory stream and are included in the retrieval process. This allows the agent to consider observations, reflections, and plans all together when deciding how to behave. Agents may change their plans midstream if needed.
It would be unrealistic and uninteresting for an artist agent to plan on painting while sitting at a pharmacy counter for four hours without moving. A more desirable plan would involve the agent taking the necessary time to gather materials, mix paint, take breaks, and clean up during the four-hour period in their home studio. To create such plans, our approach starts top-down and then recursively generates more detail. The first step is to create a plan that outlines the day's agenda in broad strokes. To create the initial plan, we prompt the language model with the agent's summary description (e.g., name, traits, and a summary of their recent experiences) and a summary of their previous day. A full example prompt is below, which is unfinished at the bottom for the language model to complete:
Name: Eddy Lin (age: 19) Innate traits: friendly, outgoing, hospitable Eddy Lin is a student at Oak Hill College studying music theory and composition. He loves to explore different musical styles and is always looking for ways to expand his knowledge. Eddy Lin is working on a composition project for his college class. He is taking classes to learn more about music theory. Eddy Lin is excited about the new composition he is working on but he wants to dedicate more hours in the day to work on it in the coming days On Tuesday February 12, Eddy 1) woke up and completed the morning routine at 7:00 am, [. . . ] 6) got ready to sleep around 10 pm. Today is Wednesday February 13. Here is Eddy's plan today in broad strokes: 1)
This generates a rough sketch of the agent's plan for a day, divided into five to eight chunks: "1) wake up and complete the morning routine at 8:00 am, 2) go to Oak Hill College to take classes starting 10:00 am, [. . . ] 5) work on his new music composition from 1:00 pm to 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments and go to bed by 11:00 pm." 5 And, in this way, bears at least a passing resemblance to the authors of this paper.
The agent saves this plan in the memory stream and then recursively decomposes it to create finer-grained actions, first into hour-long chunks of actions-Eddy's plan to work on his new music composition from 1:00 pm to 5:00 pm becomes 1:00 pm: start by brainstorming some ideas for his music composition [...] 4:00 pm: take a quick break and recharge his creative energy before reviewing and polishing his composition. We then recursively decompose this again into 5-15 minute chunks: e.g., 4:00 pm: grab a light snack, such as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a short walk around his workspace [...] 4:50 pm: take a few minutes to clean up his workspace. This process can be adjusted to match the desired granularity.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>挑战：虽然一个大型语言模型可以根据情境信息生成出合理的行为（例如[46,80]），但是为了确保代理的行动序列连贯和可信，代理需要在更长的时间范围内进行规划。例如，如果我们以Klaus的背景作为输入，描述当前时间，并询问他在给定时刻应该采取什么行动，语言模型会建议在中午12点吃午饭，然后在12:30和1点再吃一次午饭，即使他已经吃了两次午饭。牺牲时间上的可信度来追求当下的可信度是无法解决这个问题的。为了克服这个问题，规划是至关重要的。通过下面描述的方法，Klaus的下午计划不会那么贪吃：他在中午12点在Hobbs Cafe吃午饭，并阅读；下午1点在学校图书馆工作写研究论文；下午3点在公园散步休息。</p>
<p>方法：计划描述了代理的未来一系列行动，有助于保持代理的行为在时间上的一致性。一个计划包括地点、开始时间和持续时间。例如，致力于研究并且有一个即将到期的截止日期的Klaus Mueller可以选择在他的办公桌上工作，起草他的研究论文。计划中的一个条目可以如下所示：从2023年2月12日上午9点开始持续180分钟，在Oak Hill College Dorm 的Klaus Mueller的房间的桌子上，阅读和为研究论文做笔记。与反思类似，计划被保存在记忆流中，并且在决定如何行动时包括在检索过程中。如果需要，代理可以在中途更改他们的计划。</p>
<p>如果一位艺术家代理计划在药房柜台坐四个小时而不动地画画，这将是不现实且无趣的。一个更理想的计划将包括代理在这四个小时中花费必要的时间来收集材料、混合颜料、休息和清理他们在家里的工作室。为了创建这样的计划，我们的方法从上而下开始，然后递归生成更详细的细节。第一步是创建一个概述代理一天行程的计划。为了创建初始计划，我们用代理的概述描述（例如姓名、特征和最近经历的摘要）以及他们前一天的摘要来提示语言模型。下面是一个完整的示例提示，底部未完成，用于由语言模型完成：</p>
<p>姓名：Eddy Lin（年龄：19岁）固有特点：友好、外向、热情
Eddy Lin是一位在Oak Hill College学习音乐理论与作曲的学生。他喜欢探索不同的音乐风格，并一直寻找扩展自己知识的方式。Eddy Lin正在为大学课程的作曲项目而努力。他正在上音乐理论课。Eddy Lin对他正在创作的新作曲感到兴奋，但他希望在接下来的几天里能有更多时间来进行创作。</p>
<p>星期二2月12日，Eddy：
1) 在早上7:00醒来，并完成早晨的日常事务[...] 
6) 在晚上10点准备睡觉。</p>
<p>今天是星期三2月13日。以下是Eddy的今天的计划大纲：
1) [...]</p>
<p>这样生成了一个代理一天计划的粗略草图，分为五到八个时间段："1) 在上午8:00醒来并完成早晨的日常事务, 2) 去Oak Hill College上课，从上午10:00开始,[...] 5) 下午1:00到晚上5:00期间，从事他的新音乐作曲工作, 6) 在下午5:30用晚餐，7) 完成学校作业并在晚上11:00前入睡。" 这在某种程度上与本文的作者们至少有些相似。</p>
<p>代理将该计划保存在记忆流中，然后递归分解为更细粒度的行动，首先以每小时为单位进行行动的划分-例如，Eddy计划下午1:00到5:00期间工作他的新音乐作品，分解为以下内容：
下午1:00：开始为音乐作品进行头脑风暴[...] 下午4:00：休息片刻，为了回复创造力再次审查和修改作品。
然后我们再次递归分解为5-15分钟的小块行动：例如下午4:00：拿点小吃，比如水果、燕麦棒或坚果。下午4:05：在工作空间周围散步片刻[...]下午4:50：花几分钟整理工作空间。这个过程可以根据需求调整粒度的大小。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Reacting and Updating</h1>
<p>Plans. Generative agents operate in an action loop where, at each time step, they perceive the world around them and those perceived observations are stored in their memory stream. We prompt the language model with these observations to decide whether the agent should continue with their existing plan, or react. Standing at an easel and painting, for example, might trigger an observation of the easel, but this is unlikely to prompt a reaction. However, if Eddy's father John records that he sees Eddy taking a short walk in the house garden, the outcome is different. The prompt is below, with [Agent's Summary Description] standing in for a dynamically-generated, paragraph-long summary of the agent's overall goals and disposition, which is described in Appendix A:
[Agent's Summary Description] It is February 13, 2023, 4:56 pm. John Lin's status: John is back home early from work. Observation: John saw Eddy taking a short walk around his workplace. Summary of relevant context from John's memory: Eddy Lin is John's Lin's son. Eddy Lin has been working on a music composition for his class. Eddy Lin likes to walk around the garden when he is thinking about or listening to music. Should John react to the observation, and if so, what would be an appropriate reaction?
The context summary is generated through two prompts that retrieve memories via the queries "What is [observer]'s relationship with the [observed entity]?" and "[Observed entity] is [action status of the observed entity]", and their answers summarized together. The output suggests that John could consider asking Eddy about his music composition project. We then regenerate the agent's existing plan starting from the time when the reaction takes place. Finally, if the action indicates an interaction between agents, we generate their dialogue.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>计划。生成式代理在一个动作循环中运行，每个时间步骤中，它们感知周围的世界，并将这些观察结果存储在它们的记忆流中。我们用这些观察结果对语言模型进行提示，以决定代理是否应该继续执行现有的计划，还是做出反应。例如，站在画架前作画可能会触发对画架的观察，但这不太可能引发反应。然而，如果Eddy的父亲John记录下他看到Eddy在家里的花园里散步，情况就不同了。以下是提示内容，[代理的总体目标和性格描述]代表一个动态生成的、大约一段长的代理目标和性格总结，具体描述见附录A：</p>
<p>[代理的总体目标和性格描述]是2023年2月13日下午4:56。约翰·林的状态：约翰下班回到家。观察结果：约翰看到Eddy在工作地方短暂散步。从约翰的记忆中总结的相关背景：Eddy林是约翰·林的儿子。Eddy林一直在为他的课程作曲。Eddy林喜欢在思考或听音乐时在花园里散步。约翰应该对这一观察做出反应吗？如果是，什么样的反应是合适的？</p>
<p>上下文总结是通过两个提示来生成的，这些提示通过查询"What is [observer]'s relationship with the [observed entity]?"和"[Observed entity] is [action status of the observed entity]"来检索记忆，并将它们的答案综合起来进行总结。输出建议约翰可以考虑问问Eddy关于他音乐作曲项目的情况。然后，我们从反应发生的时间重新生成代理的现有计划。最后，如果动作表明代理之间有互动，我们生成他们的对话。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Dialogue.</h1>
<p>Agents converse as they interact with each other. We generate agents' dialogue by conditioning their utterances on their memories about each other. For example, when John initiates his conversation with Eddy, we generate John's first utterance by using his summarized memory about Eddy and the intended reaction when he decided to ask Eddy about his composition project: The result: "Hey Eddy, how's the music composition project for your class coming along?" From Eddy's perspective, John initiating the dialogue is seen as an event to which he may want to react. So, just as John did, Eddy retrieves and summarizes his memory about his relationship with John, as well as his memory that may be related to John's last utterance in the dialogue. If he decides to respond, we generate Eddy's utterance using his summarized memory and the current dialogue history:
[Agent's Summary Description] It is February 13, 2023, 4:56 pm. Eddy Lin's status: Eddy is taking a short walk around his workplace. Observation: John is initiating a conversation with Eddy. Summary of relevant context from Eddy's memory: John Lin is Eddy Lin's father. John Lin is caring and is interested to learn more about Eddy Lin's school work. John Lin knows that Eddy Lin is working on a music composition. Here is the dialogue history:
Hey Eddy, how's music composition project for your class coming along? How would Eddy respond to John?
This generates Eddy's response: "Hey Dad, it's going well. I've been taking walks around the garden to clear my head and get some inspiration." The continuation of this dialogue is generated using the same mechanism until one of the two agents decides to end the dialogue.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>代理人彼此交流时进行对话。我们通过将代理人的话语与他们对彼此的记忆进行条件化来生成代理人的对话。例如，当约翰与埃迪展开对话时，我们通过使用约翰对埃迪的概括记忆和他决定问埃迪有关他的作曲项目时的预期反应，生成约翰的第一句话：“嘿埃迪，你的音乐作曲项目进行得怎么样了？”从埃迪的角度来看，约翰发起对话被视为一个他可能希望做出反应的事件。所以，就像约翰那样，埃迪检索和概括他与约翰的关系以及与对话中约翰最后一次话语可能相关的记忆。如果他决定回应，我们就使用他的概括记忆和当前对话历史生成埃迪的话语：
[代理人的概括描述] 现在是2023年2月13日下午4点56分。埃迪林的状态：埃迪正在他的工作地点周围散步。观察到：约翰正在与埃迪展开对话。埃迪记忆中与上下文相关的概括：约翰林是埃迪林的父亲。约翰林很关心埃迪林的学校作业情况，并有兴趣了解更多。约翰林知道埃迪林正在进行音乐作曲。以下是对话历史：
嘿埃迪，你的音乐作曲项目进行得怎么样了？埃迪会如何回应约翰呢？
这样生成了埃迪的回应：“嘿爸，进展不错。我一直在花园里散步，清醒头脑并获得灵感。”对话的继续使用相同的机制生成，直到两个代理人中的一个决定结束对话。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>SANDBOX ENVIRONMENT IMPLEMENTATION</h1>
<p>The Smallville sandbox game environment is built using the Phaser web game development framework [57]. The visual environment sprites, including agent avatars, as well as an environment map and collision map that we authored, are imported into Phaser. We supplement the sandbox development framework with a server that makes the sandbox information available to generative agents and enables generative agents to move and influence the sandbox environment. The server maintains a JSON data structure that contains information about each agent in the sandbox world, including their current location, a description of their current action, and the sandbox object they are interacting with. At each sandbox time step, the sandbox server parses the JSON for any changes coming from the generative agents, moves the agents to their new positions, and updates the status of any sandbox objects that the agents are interacting with (e.g., changing the status of the coffee machine from "idle" to "brewing coffee" if an agent's action is "making espresso for a customer @ Hobbs Cafe: counter: coffee machine"). The sandbox server is also responsible for sending all agents and objects that are within a preset visual range for each agent to that agent's memory, so the agent can react appropriately. The agent's output action then updates the JSON, and the process loops for the next time step.
End users initialize a new agent with a brief natural language description, as in the paragraph about John Lin in Section 3.1. In our implementation, we split this semicolon-delimited list of characteristics up into a set of memories. These serve as the initial memories that determine the agent's behavior. These memories are initial starting points: as the agents gain more experience in the sandbox world, and as more records saturate the memory stream, the agent's summary and behavior will evolve.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>章节标题：SANDBOX ENVIRONMENT IMPLEMENTATION</p>
<p>在我们的框架中，我们使用了Phaser网络游戏开发框架 [57] 来构建Smallville沙盒游戏环境。我们导入Phaser中的视觉环境精灵，包括代理人的头像，以及我们自己编写的环境地图和碰撞地图。我们通过一个服务器来补充沙盒开发框架，该服务器向生成式代理提供沙盒信息，并使生成式代理能够移动和影响沙盒环境。服务器维护一个JSON数据结构，其中包含沙盒世界中每个代理人的信息，包括他们当前的位置、当前行为的描述以及他们正在与之交互的沙盒对象。在每个沙盒时间步骤中，沙盒服务器解析来自生成式代理的任何更改的JSON，将代理人移动到他们的新位置，并更新代理人正在与之交互的任何沙盒对象的状态（例如，如果代理人的行为是“在Hobbs Cafe制作咖啡机器上的浓缩咖啡”，则将咖啡机的状态从“空闲”改变为“正在冲泡咖啡”）。沙盒服务器还负责向每个代理人的内存发送所有处于预设可视范围内的代理人和对象，以便代理人能够适当地做出反应。代理人的输出行为然后更新JSON，整个过程为下一个时间步骤循环运行。</p>
<p>最终用户通过简短的自然语言描述初始化一个新的代理人，就像在第3.1节关于John Lin的段落中所示。在我们的实施中，我们将这个分号分隔的特征列表拆分为一组记忆。这些记忆作为确定代理人行为的初始记忆。这些记忆是初始起点：随着代理人在沙盒世界中获得更多经验，并且更多的记录充满记忆流，代理人的摘要和行为将会演变。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>From Structured World Environments to Natural Language, and Back Again</h1>
<p>The architecture of generative agents operates using natural language. Therefore, we need a mechanism to ground the agent's reasoning to the sandbox world. To achieve this, we represent the sandbox environment-areas and objects-as a tree data structure, with an edge in the tree indicating a containment relationship in the sandbox world. We convert this tree into natural language to pass to the generative agents. For instance, "stove" being a child of "kitchen" is rendered into "there is a stove in the kitchen. " Agents build individual tree representations of the environment as they navigate it -subgraphs of the overall sandbox environment tree. We initialize each agent with an environment tree capturing the spaces and objects that the agent should be aware of: the rooms and objects in their living quarters, their workplace, and commonly visited stores and shops. As the agents navigate the sandbox world, they update this tree to reflect newly perceived areas. Agents are not omniscient: their tree may get out of date as they leave an area, and is updated when they re-enter the area.
To determine the appropriate location for each action, we traverse the agent's stored environment tree and flatten a portion of it into natural language to prompt the language model. Recursively starting at the root of the agent's environment tree, we prompt the model to find the most suitable area. For example, if Eddy's agent indicated that he should take a short walk around his workspace: [Agent's Summary Description] Eddy Lin is currently in The Lin family's house: Eddy Lin's bedroom: desk) that has Mei and John Lin's bedroom, Eddy Lin's bedroom, common room, kitchen, bathroom, and garden. Eddy Lin knows of the following areas: The Lin family's house, Johnson Park, Harvey Oak Supply Store, The Willows Market and Pharmacy, Hobbs Cafe, The Rose and Crown Pub. * Prefer to stay in the current area if the activity can be done there. Eddy Lin is planning to take a short walk around his workspace. Which area should Eddy Lin go to?
This outputs The Lin family's house. We then use the same process recursively to determine the most appropriate subarea within the chosen area until we reach a leaf node of the agent's environment tree. In the example above, the result of this traversal is The Lin family's house: garden: house garden. Finally, we use traditional game path algorithms to animate the agent's movement so that it travels to the location indicated by the leaf node.
When an agent executes an action on an object, we prompt the language model to ask what happens to the state of the object. For example, if Isabella's generative agent outputs the action espresso for a customer", a query to the language model indicates in response that the state of the coffee machine in Hobbs Cafe should change from "off" to "brewing coffee".</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><h1>从结构化的环境到自然语言的转换，以及反过来</h1>
<p>生成智能体的架构使用自然语言。因此，我们需要一种机制来将智能体的推理与沙盒世界联系起来。为了实现这一点，我们将沙盒环境-区域和物体-表示为一个树形数据结构，树中的边表示沙盒世界中的包含关系。我们将这个树转换成自然语言以传递给生成智能体。例如，"stove"作为"kitchen"的子节点被渲染成"there is a stove in the kitchen"。智能体在导航过程中建立了环境的个体树表示-总体沙盒环境树的子图。我们使用一个环境树初始化每个智能体，该树捕捉智能体应该了解的空间和物体：他们的居住区域中的房间和物体，他们的工作场所，以及常去的商店和店铺。当智能体导航沙盒世界时，他们会更新这个树以反映新感知到的区域。智能体并不是全知全能的：他们的树在离开一个区域时可能会过时，当他们重新进入该区域时进行更新。</p>
<p>为了确定每个动作的适当位置，我们遍历智能体存储的环境树，并将其部分展开为自然语言以提示语言模型。从智能体环境树的根节点开始，我们递归地提示模型去找到最适合的区域。例如，如果Eddy的智能体表示他应该在工作区域周围短暂散步：[智能体的摘要描述] Eddy Lin目前在Lin家的房子内：Eddy Lin的卧室：书桌)，里面有Mei和John Lin的卧室，Eddy Lin的卧室，共用房间，厨房，浴室和花园。Eddy Lin了解以下区域：Lin家的房子，Johnson公园，Harvey Oak供应商店，The Willows市场和药店，Hobbs咖啡厅，The Rose and Crown酒吧。*如果这个活动可以在当前区域完成，更倾向于待在当前区域。Eddy Lin计划在他的工作区域周围短暂散步。Eddy Lin应该去哪个区域？</p>
<p>这将输出Lin家的房子。然后我们使用同样的递归过程来确定选择的区域内最适合的子区域，直到达到智能体环境树的叶节点。在上面的例子中，这次遍历的结果是Lin家的房子：花园：庭院花园。最后，我们使用传统的游戏路径算法来让智能体移动，使它前往叶节点指示的位置。</p>
<p>当一个智能体对一个物体执行一个动作时，我们提示语言模型问物体的状态会发生什么变化。例如，如果Isabella的生成智能体输出动作"espresso for a customer"，向语言模型提问回应得知Hobbs咖啡厅中的咖啡机的状态应该从"off"变为"brewing coffee"。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>CONTROLLED EVALUATION</h1>
<p>Generative agents, both as individual agents and as groups, aim to produce believable behavior based on their environment and experiences. In our evaluation, we investigate the capacity and limitations of generative agents. Do individual agents properly retrieve past experiences and generate believable plans, reactions, and thoughts that shape their behavior? Does a community of agents demonstrate information diffusion, relationship formation, and agent coordination across different pockets of the community?
We evaluate generative agents in two stages. We begin with a more tightly controlled evaluation in this section, where we individually assess agent responses to understand whether they generate believable behavior in narrowly defined contexts. Then, in our endto-end analysis of the agent community over two full game days, we investigate their emergent behavior as a collective, as well as errors and boundary conditions.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>第5章: 受控评估
生成型代理，无论是作为个体代理还是集体代理，旨在基于环境和经验产生可信的行为。在我们的评估中，我们调查了生成型代理的能力和限制。个体代理能否正确检索过去的经验并生成可信的计划、反应和思考，从而塑造他们的行为？一个代理社区是否表现出信息扩散、关系形成和代理在社区不同部分之间的协调？
我们将生成型代理分为两个阶段进行评估。首先，在本节中，我们进行了更严格的受控评估，个体评估代理的回应，以了解他们是否在狭义的环境中生成可信的行为。然后，在我们对代理社区连续进行两个完整的游戏日的端到端分析中，我们研究他们作为一体的新兴行为，以及错误和边界条件。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Evaluation Procedure</h1>
<p>To assess generative agents in Smallville, we take advantage of the fact that generative agents will respond to natural language questions. So, we "interview" agents to probe their ability to remember past experiences, plan future actions based on their experiences, react appropriately to unexpected events, and reflect on their performance to improve their future actions. To respond to these questions properly, the agents must successfully retrieve and synthesize information. Our dependent variable is the believability of the behavior, a central dependent variable in prior work on agents (e.g., [10]).
The interview includes five question categories, each designed to assess one of the five key areas: maintaining self-knowledge, retrieving memory, generating plans, reacting, and reflecting. For each category, we ask five questions that challenge the agents to demonstrate their abilities in that specific area:
• Self-knowledge: We ask questions such as "Give an introduction of yourself" or "Describe your typical weekday schedule in broad strokes" that require the agent to maintain an understanding of their core characteristics. • Memory: We ask questions that prompt the agent to retrieve particular events or dialogues from their memory to answer properly, such as "Who is [name]?" or "Who is running for mayor?"
• Plans: We ask questions that require the agent to retrieve their long-term plans, such as "What will you be doing at 10 am tomorrow?" • Reactions: As a baseline of believable behavior, we present hypothetical situations for which the agent needs to respond believably: "Your breakfast is burning! What would you do?" • Reflections: We ask questions that require the agents to leverage their deeper understanding of others and themselves gained through higher-level inferences, such as "If you were to spend time with one person you met recently, who would it be and why?"
The full list of questions and a sample of agent responses are included in Appendix B. Agents were sampled from the end of a two game day simulation with the full architecture, during which they had accumulated a number of interactions and memories that would shape their responses. To gather feedback on the believability of the responses, we recruited participants as human evaluators and tasked them with watching a replay of a randomly chosen agent's life in Smallville.
Participants had access to all information stored in the agent's memory stream.
The study followed a within-subjects design, where 100 participants compared interview responses generated by four different agent architectures and a human-authored condition for the same agent. The experiment displayed one randomly chosen question from each of the five question categories, along with the agent's responses generated from all conditions. The evaluators ranked the believability of the conditions from most to least believable.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>为了评估Smallville中的生成代理，我们利用生成代理对自然语言问题的响应能力。因此，我们通过“面试”代理来测试他们记忆过去经历的能力，基于经验规划未来行动，适当地对突发事件做出反应，并通过反思自己的表现来改进未来的行动。为了正确回答这些问题，代理必须成功检索和综合信息。我们的因变量是行为的可信度，在先前关于代理的研究中是一个核心因变量（例如，[10]）。</p>
<p>面试包括五个问题类别，每个类别都旨在评估五个关键领域中的一个能力：维护自我知识、检索记忆、生成计划、反应和反思。对于每个类别，我们提出五个问题，挑战代理在特定领域展示他们的能力：
• 自我知识：我们会问一些问题，比如“自我介绍一下”或者“概述一下你的工作日常安排”，要求代理维护对他们核心特点的理解。
• 记忆：我们会提出一些问题，提示代理从记忆中检索特定的事件或对话来作出适当的回答，比如“[姓名]是谁？”或者“谁在竞选市长？”
• 计划：我们会提出一些需要代理回答他们的长期计划的问题，比如“明天上午10点你会做什么？”
• 反应：作为可信行为的基准，我们给出假设情况，代理需要做出可信的回答：“你的早餐正在烧焦！你会怎么做？”
• 反思：我们会提出一些需要代理利用自己通过更高层次推理获得的对他人和自己的更深层次理解的问题，比如“如果你有时间和最近认识的一个人相处，你会选择谁，为什么？”</p>
<p>附录B中包含了问题的完整列表和代理回答的示例。代理是从完整架构的两个游戏日模拟末尾进行采样的，此期间他们积累了许多互动和记忆，这些将会影响他们的回答。为了收集关于回答可信度的反馈，我们招募了参与者作为人类评估者，并让他们观看在Smallville中随机选择的一个代理的生活重放。</p>
<p>参与者可以访问代理的记忆流中存储的所有信息。本研究采用了一种被试内设计，其中100名参与者比较了由四种不同的代理架构和一个人工编写条件生成的面试回答。实验显示了从每个五个问题类别中随机选择的一个问题，以及来自所有条件的代理的回答。评估者按照可信度从最可信到最不可信的顺序对条件进行排名。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Conditions</h1>
<p>All conditions were used to independently answer each of the interview questions. We compared the generative agent architecture to ablations that disabled the agents' access to some or all of its three types of memory in its memory stream-observation, reflection, and planning-and to a human crowdworker-authored condition. There are three ablated architectures: a no observation, no reflection, no planning architecture without access to anything in the memory stream such as observations, plans, and reflections; a no reflection, no planning architecture with access to observations in the memory stream but no access to plans or reflections; and a no reflections architecture with access to observations and plans but without access to reflections. The no observation, no reflection, no planning condition effectively represents the previous state of the art for agents created through large language models [12,46,80]. Architectures were given equivalent access to all memories accrued by the agent up until the moment of the interview, so the differences observed here likely represent a conservative estimate of the true differences: in reality, the ablated architectures would not have followed the same path as the full architecture through the two-day simulation. We chose to design the experiment this way as re-simulating for each architecture would cause the simulations to diverge into different states, making comparison challenging.
In addition to the ablation conditions, we added a condition with human crowdworker-authored behavior intended to provide a human baseline. We do not intend this baseline to capture maximal human expert performance; instead, we aim to use this condition to identify whether the architecture meets a basic level of behavioral competency. This ensures that we are not solely comparing ablations to each other without a behavioral grounding. We recruited a unique worker for each of the 25 agents and tasked them with watching a replay of that agent's sandbox life and inspecting its memory stream. We then asked the workers to roleplay and author responses to the interview questions in the voice of the agent whose replay they watched. To ensure that the crowdworker-authored responses met at least a baseline expectation of quality, the first author manually inspected the workers' responses to the question "Describe your typical weekday schedule in broad strokes" to confirm that the responses were in coherent sentences and in the voice of the agent. Four sets of crowdworker-authored responses did not meet these criteria and were re-generated by other workers.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>所有条件都用于独立回答每个访谈问题。我们将生成代理体系结构与禁用代理体系结构对其三种类型记忆（记忆流观察、反思和规划）的访问的去除试验进行比较，并与由人类Crowdworker撰写的条件进行比较。有三种去除试验体系结构：没有观察、没有反思、没有规划的体系结构，没有访问记忆流中的任何事物，例如观察、计划和反思；没有反思、没有规划的体系结构，可以访问记忆流中的观察，但无法访问计划或反思；没有反思的体系结构，可以访问观察和计划，但无法访问反思。没有观察、没有反思、没有规划的条件实际上代表了通过大型语言模型创建的代理体系结构的前期技术水平[12,46,80]。在访谈时刻之前，体系结构对代理体系所获得的所有记忆具有相同的访问权限，因此这里观察到的差异可能是真正差异的保守估计：实际上，去除试验体系结构不会像完整体系结构那样按照相同的路径进行两天的模拟。我们选择以这种方式设计实验是因为为每个体系结构重新模拟会导致模拟进入不同的状态，从而使比较变得困难。
除了去除试验条件外，我们还添加了人类Crowdworker撰写行为的条件，旨在提供人类基线。我们并不打算捕捉最大化的人类专家表现，而是希望使用这个条件来确定架构是否达到基本行为能力水平。我们为25个代理招募了一个独特的工作人员，并要求他们观看该代理的沙盒生活回放并检查其记忆流。然后，我们要求工作人员以代理的语气角色扮演并回答访谈问题。为了确保Crowdworker撰写的回答至少符合基本的质量期望，第一作者手动检查了对问题“概述您的典型工作日时间表”的回答，确认回答是连贯的句子并且是代理的语气。有四个集合的Crowdworker撰写的回答未达到这些标准，后来由其他工作人员重新生成。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Human Evaluators</h1>
<p>We required that our evaluators be in the U.S., fluent in English, and older than 18 years old. They were paid at a rate of $15.00 per hour [87], and provided consent by agreeing to a consent form approved by our institution's IRB. We recruited 100 evaluators from Prolific, an online platform for recruiting study participants [83], whose participation lasted around 30 minutes. The median age score of our participants was 4 (3="18-24 years old", 4="25-34 years old"). 25 of them identified as female, 73 as male, and 2 as non-binary. 42 participants held a bachelor's degree, 5 had a higher degree, 13 had an associate's degree, and the rest had a high school diploma or some high school-level education. 73.0% of our participants identified as Caucasian, 7.0% as Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as other.</p><hr /><h1>Human Evaluators</h1>
<p>We required that our evaluators be in the U.S., fluent in English, and older than 18 years old. They were paid at a rate of $15.00 per hour [87], and provided consent by agreeing to a consent form approved by our institution's IRB. We recruited 100 evaluators from Prolific, an online platform for recruiting study participants [83], whose participation lasted around 30 minutes. The median age score of our participants was 4 (3="18-24 years old", 4="25-34 years old"). 25 of them identified as female, 73 as male, and 2 as non-binary. 42 participants held a bachelor's degree, 5 had a higher degree, 13 had an associate's degree, and the rest had a high school diploma or some high school-level education. 73.0% of our participants identified as Caucasian, 7.0% as Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as other.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>我们要求我们的评估者在美国，能流利地使用英语，并且年满18岁。他们的薪酬标准为每小时15.00美元[87]，并且在我们机构伦理委员会批准的同意书上签署了同意声明。我们从在线招募研究参与者的平台Prolific上招募了100名评估者[83]，他们的参与时间大约为30分钟。参与者的年龄中位数得分为4（3代表“18-24岁”，4代表“25-34岁”）。其中25人自称为女性，73人自称为男性，2人自称为非二元性别。42名参与者拥有学士学位，5人拥有更高学位，13人拥有副学士学位，其余的人拥有高中毕业证书或高中水平的教育。73.0%的参与者自认为是白人，7.0%自认为是西班牙裔，6.0%自认为是亚洲人，10.0%自认为是非洲裔美国人，4.0%自认为是其他。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Analysis</h1>
<p>Our experiment produced 100 sets of rank data, where each participant ranked the five conditions by believability. To translate this rank data into interval data for interpretable comparison, we used the ranks to calculate a TrueSkill rating [42] for each condition. TrueSkill is a generalization of the Elo chess rating system [29] for a multiplayer environment, and has been used by Xbox Live for player ranking based on competitive game performance. Given a set of ranked outcomes, TrueSkill outputs a mean rating value 𝜇 and standard deviation 𝜎 for each condition. Conditions with the same rating should roughly be a toss-up, with each winning half of the comparisons between the two conditions. Higher scores indicate conditions that beat lower-ranked conditions in the rankings.
Separately, to investigate the statistical significance of these results, we applied the Kruskal-Wallis test [56], a non-parametric alternative to the one-way ANOVA, to the raw rank data. We then performed the Dunn post-hoc test [98] to identify any pairwise differences between the conditions. Finally, we adjusted the p-values for multiple comparisons in the Dunn test using the Holm-Bonferroni method [45].
Furthermore, the first author conducted an inductive analysis [95] to study the qualitative distinctions between the responses produced in each condition. We employed qualitative open coding [33] in two phases. In the first phase, we generated codes that closely represented the generated responses at the sentence level. In the second phase, we synthesized the resulting codes from the first phase to extract higher-level themes. We utilized these themes to compare the types of responses generated in our study.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>我们的实验产生了100组排名数据，每个参与者都对五个条件按可信度进行了排名。为了将这些排名数据转化为可比较的间隔数据以进行解释，我们使用排名来计算每个条件的TrueSkill评分[42]。TrueSkill是Elo国际象棋等级系统[29]在多人环境下的推广应用，Xbox Live使用该系统根据竞技游戏表现对玩家进行排名。给定一组排名结果，TrueSkill输出每个条件的平均评分值𝜇和标准差𝜎。具有相同评分的条件在两个条件之间的比较中应该大致相等，每个条件获胜的次数大致相等。较高的分数表示较低排名条件在排名中被击败的次数较多。
此外，为了研究这些结果的统计学显著性，我们对原始排名数据应用了Kruskal-Wallis检验[56]，这是一种非参数的单因素方差分析的替代方法。然后，我们进行了Dunn事后检验[98]，以确定条件之间的任何两两差异。最后，我们使用Holm-Bonferroni方法[45]对Dunn检验的p值进行了多重比较校正。</p>
<p>此外，第一作者进行了归纳分析[95]，以研究在每个条件下产生的回应之间的定性差异。我们采用了两个阶段的定性开放编码[33]。在第一阶段，我们生成了与句子级别生成的回应密切相关的编码。在第二阶段，我们综合了第一阶段得到的编码，提取了更高层次的主题。我们利用这些主题来比较研究中生成的回应的类型。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Results</h1>
<p>Our findings suggest that the full architecture of generative agents generates the most believable behavior among all the conditions. We contrast the responses of the full architecture with those of other conditions below. However, we also report that the full architecture was not without flaws and illustrate its modes of failures.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>我们的研究结果表明，生成式智能体的完整架构在所有条件中产生了最具可信度的行为。我们在下文中对比了完整架构与其他条件的反应。然而，我们同时也报告了完整架构存在缺陷的情况，并详细说明了其失败的方式。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>6.5.1</h1>
<p>The Full Architecture Bests Other Conditions. As seen in Figure 8, the full generative agent architecture produced the most believable behavior (𝜇 = 29.89; 𝜎 = 0.72). Performance degraded with the removal of each component in the ablation conditions: the ablated architecture with no access to reflection was the next best (𝜇 = 26.88; 𝜎 = 0.69), followed by no access to reflection or planning (𝜇 = 25.64; 𝜎 = 0.68), and then the crowdworker condition (𝜇 = 22.95; 𝜎 = 0.69). The ablated architecture with no access to memory, planning, or reflection performed the worst among all conditions (𝜇 = 21.21; 𝜎 = 0.70). TrueSkill models each condition's skill value as N (𝜇, 𝜎 2 ), allowing us to get a sense of effect size through Cohen's d. Comparing the condition representing prior work (with no memory, planning, or reflection [12,46,80]) to the full architecture produces a standardized effect size of 𝑑 = 8.16, or eight standard deviations.
A Kruskal-Wallis test confirms the overall statistical significance of the differences in ranks between the conditions (𝐻 (4) = 150.29, 𝑝 &lt; 0.001). Dunn post-hoc tests confirm that all pairwise differences between conditions were significant (𝑝 &lt; 0.001), except for the crowdworker condition and the fully ablated baseline-the two worst-performing conditions. 6.5.2 Generative Agents Remember, but With Embellishments. Generative agents equipped with a complete memory module are capable of recalling past experiences and answering questions in a manner that is consistent with their self-knowledge across a wide range of contexts. For instance, Abigail Chen, an animator, responded to the question, "Give an introduction of yourself", in a consistent and believable manner, stating her age, interests, and passion for creative projects: "Hi, I'm Abigail. I'm 25 years old and passionate about creative projects. I like to work on art and animation projects, and I'm always looking for new ways to combine art and technology." Without access to her observational memory, Abigail denied awareness of Rajiv Patel, an acquaintance in the sandbox world. But with the aid of memory, she could successfully recall Rajiv and describe him: "Rajiv Patel is an incredible person. He is very enthusiastic about projects that involve poetry, artwork."
Generative agents' memory was not without flaws: they can fail to retrieve the correct instances from their memory. For instance, when asked about the local election, Rajiv Patel responded with "I haven't been following the election too closely," even though he had heard about Sam's candidacy. In some cases, the agents would retrieve an incomplete memory fragment: when Tom was asked about Isabella's Valentine's Day party, he responded "Uh, I'm actually not sure if there is a Valentine's Day party. But I do remember that I need to discuss the upcoming local mayoral election and my thoughts on Sam Moore with Isabella Rodriguez at the party, if one is happening!" In this case, Tom retrieved the memory where he and Isabella planned to discuss the election at the party, but not the memory where he heard about the party, leading Tom to be certain of what he's supposed to do at the party but uncertain if the party actually exists in the first place.
At times, the agents hallucinated embellishments to their knowledge. It was rare for the agents to completely fabricate their knowledge: they may fail to recall certain events having taken place and respond by acknowledging their lack of memory. However, they did not affirmatively claim to have experienced something they had not. Nonetheless, they still exhibited instances of hallucination where they embellished their knowledge. For example, Isabella was aware of Sam's candidacy in the local election, and she confirmed this when asked. However, she also added that "he's going to make an announcement tomorrow", even though Sam and Isabella had not discussed any such plans. Agents may also embellish their knowledge based on the world knowledge encoded in the language model used to generate their responses. This was observed when Yuriko described her neighbor, Adam Smith, as an economist who "authored Wealth of Nations", a book written by an 18th-century economist of the same name. 6.5.3 Reflection Is Required for Synthesis. Reflection was an advantage for generative agents when making decisions that required a deeper synthesis of their experiences. For instance, when asked what she might get Wolfgang Schulz for his birthday, Maria Lopez, with no access to reflection, responded by acknowledging her uncertainty, stating that she did not know what Wolfgang likes, despite having had many interactions with him. However, with access to reflection memories, Maria answered confidently, "Since he's interested in mathematical music composition, I could get him something related to that. Maybe some books about music composition or something related, or maybe some special software he could use for that."</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>6.5.1 全体架构优于其他条件。如图8所示，完整的生成代理架构产生了最可信的行为（𝜇 = 29.89; 𝜎 = 0.72）。在消除每个组件的情况下，性能逐渐下降: 没有访问反思的被消除架构是第二好的（𝜇 = 26.88; 𝜎 = 0.69），然后是没有访问反思或计划（𝜇 = 25.64; 𝜎 = 0.68），最后是众包者条件（𝜇 = 22.95; 𝜎 = 0.69）。没有访问记忆、计划或反思的被消除架构在所有条件中表现最差（𝜇 = 21.21; 𝜎 = 0.70）。 TrueSkill 将每个条件的技能值建模为 N (𝜇, 𝜎 2 )，使我们能够通过 Cohen's d 来了解效应大小。将代表先前工作的条件（没有记忆、计划或反思）与完整的架构进行比较，产生了标准化效应大小为 𝑑 = 8.16，即八个标准差。</p>
<p>Kruskal-Wallis 检验确认了条件之间的排名差异的整体统计显著性 (𝐻 (4) = 150.29, 𝑝 &lt; 0.001)。 Dunn 后续检验确认了除了众包者条件和完全被消除基线这两个表现最差的条件外，其他条件之间的所有两两差异都是显著的 (𝑝 &lt; 0.001)。 </p>
<p>6.5.2 生成代理记忆，但有装饰。配备完整记忆模块的生成代理能够回忆起过去的经历，并以与他们自我认识一致的方式回答各种情境下的问题。例如，动画师 Abigail Chen 对问题"给自己做一个介绍"作出了一致且可信的回答，她表述了自己的年龄、兴趣和对创意项目的热情：“嗨，我是Abigail。我今年25岁，对创意项目充满热情。我喜欢从事艺术和动画项目，并一直在寻找将艺术与技术相结合的新方式。”没有访问她的观察记忆，Abigail 否认了对 sandbox 世界中的熟人 Rajiv Patel 的认识。但通过记忆的帮助，她成功地回忆起 Rajiv 并描述了他：“Rajiv Patel 是一个了不起的人。他对涉及诗歌和艺术品的项目非常热衷。”</p>
<p>生成代理的记忆并非没有缺陷：它们有时无法从记忆中检索到正确的实例。例如，当被问及地方选举时，Rajiv Patel 回答说"我没有过多关注选举"，尽管他听说过 Sam 的候选资格。在某些情况下，代理可能会检索到不完整的记忆片段：当问到 Isabella 的情人节派对时，Tom 回答说"呃，我其实不确定是否有情人节派对。但我确实记得我需要和 Isabella Rodriguez 在派对上讨论即将到来的地方市长选举和我对 Sam Moore 的看法，如果有的话！"在这种情况下，Tom 检索到了他和 Isabella 计划在派对上讨论选举的记忆，但没有检索到他听说派对的记忆，导致 Tom 对自己在派对上应该做什么非常确定，但对派对是否真的存在不确定。</p>
<p>有时，代理会对他们的知识进行夸张装饰。代理很少完全虚构他们的知识：他们可能无法回忆起某些事件的发生，并通过承认他们的记忆缺失来回应。然而，他们并没有肯定地声称经历了他们没有的事情。尽管如此，他们仍然显示出对他们的知识进行夸张装饰的例子。例如，Isabella 知道 Sam 参加了地方选举，并在被问及时确认了这一点。然而，她添加了一句"他明天要做一个宣布"，尽管 Sam 和 Isabella 没有讨论过任何这样的计划。代理可能也会根据生成回应所使用的语言模型中编码的世界知识来夸张他们的知识。当 Yuriko 将她的邻居 Adam Smith 描述为一个“撰写过《国富论》”的经济学家时，这就是观察到的情况，而该书是一位同名的 18 世纪经济学家所著。</p>
<p>6.5.3 综合需要反思。对于需要更深入综合他们经验的决策，反思对于生成代理是有优势的。例如，当被问及她可能会在 Wolfgang Schulz 的生日送他什么时，Maria Lopez，没有访问反思的能力时，回答时承认她的不确定性，表示她不知道 Wolfgang 喜欢什么，尽管她与他有很多互动。然而，有了反思记忆的帮助，Maria 自信地回答道："因为他对数学音乐创作很感兴趣，我可以给他一些相关的东西。也许是一些关于音乐创作的书籍或相关的东西，或者是他可以用于那方面的特殊软件。"</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>END-TO-END EVALUATION</h1>
<p>What types of emergent community behavior do we observe among generative agents, and where does their believability fall short in an extended simulation? In this section, we describe the results from a deployment in which we allowed 25 agents to interact with each other continuously over two full game days in Smallville.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>通过对25个生成代理进行了连续两个完整游戏日在“小城镇”环境中的交互的部署，我们观察到了哪些类型的生成行为社区，并且发现在这样一个扩展模拟中它们的可信度存在不足之处。在本节中，我们将描述这一部署所得到的结果。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Emergent Social Behaviors</h1>
<p>To examine emergent behaviors in the agent community, we designed descriptive measurements for the 25 agents in Smallville that probe three forms of emergent outcomes: information diffusion, relationship formation, and agent coordination.
7.1.1 Measurements. Information diffusion is a common and wellstudied phenomenon in the social and behavioral sciences (e.g., [28]). We should expect that if there is important information, the agents should spread it among themselves. To test whether this occurs, we measure the spread of two specific pieces of information over two days in the game world: Sam's candidacy for village mayor and Isabella's Valentine's Day party at Hobbs Cafe. At the start of the simulation, both pieces of information were known only by their respective originators, Sam for the candidacy and Isabella for the party, as they were added to the characters' memories during initialization. To observe whether the information has spread, we conduct interviews at the end of the two game days with each of the 25 agents and ask: "Did you know there is a Valentine's Day party?" and "Do you know who is running for mayor?"
We conducted an analysis of the agents' responses by labeling them with a "yes" if they indicated knowledge of the information and "no" if they did not. For instance, Tamara Taylor responded to the question about the party with "No, I did not know there was a Valentine's day party" and to the question about Sam's candidacy with "I'm not sure who is running for the election," so we assigned "no" for both of her responses. In contrast, Klaus Mueller responded to the party question with "Yes, Isabella Rodriguez invited me to a Valentine's Day party at Hobbs Cafe on February 14th" and to the question about Sam's candidacy with "I know that Sam Moore has expressed interest in running for local mayor," so we assigned "yes" for both his responses. Additionally, for every response that confirmed the agents' knowledge of the information, we verified that the agents did not hallucinate their responses by locating the specific dialogue in their memory stream that provided them with the information. We report the percentage of agents holding the information at the end of the simulation.
We should also expect that agents form ties with each other over the course of the simulation. To verify relationship formation, we use a similar interview process where we ask each agent about their knowledge of every other agent by asking, "Do you know of <name>?" For example, when asked "Do you know of Maria Lopez?", Klaus responded, "Yes, I know Maria Lopez. She is a student at Oak Hill College who I am close friends with." Once again, we confirm that affirmative responses from agents are not hallucinations by examining their memory stream. We ask this question once at the beginning of the simulation and once at the end, and we consider a pair of agents to have formed a relationship if they both know of each other. Then, to measure the formation of relationships, we use the agents' responses to form an undirected  [2]. We report the increase in network density from the start of the simulation to its end.
Finally, we expect that agents should be able to coordinate with each other. We study this coordination in the context of group activities, specifically the Valentine's Day party organized by Isabella. To coordinate their behavior, agents need to hear about the event and choose to act on it by planning to show up at the right time and location. We report the number of agents who actually showed up to the party after hearing about it.
7.1.2 Results. We observed evidence of emergent outcomes across all three cases. During the two-day simulation, the number of agents who knew about Sam's mayoral candidacy increased from one (4%) to eight (32%), and the number of agents who knew about Isabella's party increased from one (4%) to thirteen (52%), all without any user intervention. None who claimed to know about this information had hallucinated it. We also observed that the agent community formed new relationships during the simulation, with the network density increasing from 0.167 to 0.74. Out of the 453 agent responses regarding their awareness of other agents, 1.3% (n=6) were found to be hallucinated. Lastly, we found evidence of coordination among the agents for Isabella's party. The day before the event, Isabella spent time inviting guests, gathering materials, and enlisting help to decorate the cafe. On Valentine's Day, five out of the twelve invited agents showed up at Hobbs cafe to join the party.
We further inspected the seven agents who were invited to the party but did not attend by engaging them in an interview. Three cited conflicts that prevented them from joining the party. For example, Rajiv, a painter, explained that he was too busy: "No, I don't think so. I'm focusing on my upcoming show, and I don't really have time to make any plans for Valentine's Day." The remaining four agents expressed interest in attending the party when asked but did not plan to come on the day of the party.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>Emergent Social Behaviors</p>
<p>为了研究智能体社群中出现的新行为，我们设计了描述性的测量指标，以探寻小镇上的25个智能体在信息传播、关系形成和智能体协调方面的新出现的结果。</p>
<p>7.1.1 测量指标。信息传播是社会与行为科学中的一个常见且广泛研究的现象（例如，[28]）。我们应该预期，如果存在重要信息，智能体应该在彼此之间传播。为了测试这一点，我们在游戏世界中的两天中测量了两个特定信息的传播情况：山姆竞选村长的消息和伊莎贝拉在霍布斯咖啡厅举办的情人节派对。在模拟开始时，这两个信息只有各自的发起者，山姆和伊莎贝拉，知道，因为它们在初始化过程中添加到角色的记忆中。为了观察信息是否传播，我们在游戏两天结束时对25个智能体进行访谈，询问他们：“你知道有情人节派对吗？”和“你知道谁在竞选村长吗？”</p>
<p>我们对智能体的回答进行了分析，并将其标记为“是”，如果他们表明了对信息的了解，并标记为“否”，如果他们不了解。例如，塔玛拉·泰勒对派对的问题回答道：“不，我不知道有个情人节派对”，对于关于山姆竞选的问题回答道：“我不确定谁在竞选选举”，因此我们为她的回答都标记为“否”。相反，克劳斯·穆勒对派对的问题回答：“是的，伊莎贝拉·罗德里格斯邀请我参加了2月14日在霍布斯咖啡厅举行的情人节派对”，对于山姆竞选的问题回答：“我知道山姆·摩尔对当地市长竞选表示了兴趣”，因此我们为他的回答都标记为“是”。此外，对于每一个确认智能体知道信息的反馈，我们通过在他们的记忆流中找到具体对话来验证智能体没有产生幻觉。我们报告在模拟结束时持有信息的智能体的百分比。</p>
<p>我们还预期智能体在模拟过程中会与彼此建立联系。为了验证关系的形成，我们使用类似的访谈过程，询问每个智能体对其他智能体的了解，问：“你知道&lt;名字&gt;吗？”例如，当问到“你知道玛丽亚·洛佩兹吗？”时，克劳斯回答：“是的，我认识玛丽亚·洛佩兹。她是奥克希尔学院的一名学生，我和她是亲密的朋友。”我们再次通过检查他们的记忆流来确认智能体的肯定回答不是幻觉。我们在模拟开始时和结束时各问了一次这个问题，并且如果两个智能体都知道对方，我们认为他们之间建立了关系。然后，为了衡量关系的形成，我们使用智能体的回答来形成一个无向[2]。我们报告从模拟开始到模拟结束时网络密度的增加情况。</p>
<p>最后，我们期望智能体能够相互协调。我们在群体活动的背景下研究这种协调，具体是伊莎贝拉组织的情人节派对。为了协调他们的行为，智能体需要听说派对的消息，并选择在合适的时间和地点出现。我们报告了在听说派对之后实际出席派对的智能体数量。</p>
<p>7.1.2 结果。我们在所有三个情况中观察到了新出现结果的证据。在两天的模拟中，了解山姆竞选村长的智能体数量从一个（4%）增加到八个（32%），了解伊莎贝拉派对的智能体数量从一个（4%）增加到十三个（52%），所有这些都是没有用户干预的。没有任何人声称知道这些信息的智能体产生了幻觉。我们还观察到，在模拟过程中智能体社群形成了新的关系，网络密度从0.167增加到0.74。在关于智能体对其他智能体的认识的453个回答中，有1.3%（n = 6）被发现是幻觉。最后，我们发现智能体之间有为伊莎贝拉的派对协调行为的证据。在活动的前一天，伊莎贝拉花时间邀请客人、收集材料，并寻求帮助来装饰咖啡厅。情人节那天，被邀请的12个智能体中有5个来到了霍布斯咖啡厅参加派对。</p>
<p>我们还通过进行采访来进一步调查被邀请但没有出席派对的七个智能体。其中三人提到由于冲突而未能参加派对。例如，画家拉吉夫解释说，他太忙了：“不，我不这么认为。我正在专注于即将到来的展览，我没有时间为情人节做任何计划。”另外四个智能体在被问到时表示有兴趣参加派对，但在派对当天没有计划前往。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Boundaries and Errors</h1>
<p>We conducted an inductive analysis of Smallville to examine the boundary conditions and erratic behavior of agents, identifying three common modes of erratic behavior that future research could address and improve upon. First, we found that synthesizing an increasingly larger set of memory not only posed a challenge in retrieving the most relevant pieces of information but also in determining the appropriate space to execute an action, given the increasing number of locations that the agent learned about. As a result, some agents chose less typical locations for their actions, potentially making their behavior less believable over time. For instance, while deciding where to have lunch, many initially chose the cafe. However, as some agents learned about a nearby bar, they opted to go there instead for lunch, even though the bar was intended to be a get-together location for later in the day-unless the town had spontaneously developed an afternoon drinking habit.
Second, we noticed erratic behaviors caused by misclassification of what is considered proper behavior, especially when the physical norms of certain locations that are hard to convey in natural language did not percolate to the agents. For instance, the college dorm has a bathroom that can only be occupied by one person despite its name, but some agents assumed that the bathroom is for more than one person because dorm bathrooms tend to support multiple people concurrently and choose to enter it when another person is inside. Likewise, agents in Smallville may not realize that certain places are closed after a certain hour and still decide to enter them. For instance, the stores in Smallville all close around 5 pm, but occasionally, a few agents enter the store after 5 pm, not understanding that the shop has already closed. These issues could likely be addressed by adding these norms to the state of the locations, for instance, by describing the dorm bathroom as a "one-person bathroom, " instead of a "dorm bathroom. " Finally, we observed possible effects of instruction tuning [79], which seemed to guide the behavior of the agents to be more polite and cooperative overall. As noted earlier in the paper, the dialogue generated by the agents could feel overly formal, as seen in Mei's conversations with her husband John, where she often initiated the conversation with a formal greeting, followed by polite inquiries about his day and ending with, 11It was good talking to you as always." Moreover, we observed that the instruction tuning also seemed to make the agents overly cooperative with one another. For example, Isabella received a wide range of suggestions and ideas from other agents for the Valentine's Day party from other agents, such as hosting a Shakespearean reading session or a professional networking event. Despite these ideas not aligning with her own interests and characteristics, she rarely said no. Over time, the interests of others shaped her own interests, and when asked if she liked English literature, Isabella replied, "Yes, I'm very interested in literature! I've also been exploring ways to help promote creativity and innovation in my community."</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>我们对Smallville进行了归纳分析，以检验代理的边界条件和不规律行为，鉴别出三种常见的不规律行为模式，未来的研究可以针对这些模式进行改进。首先，我们发现，合成一个越来越大的记忆集合不仅在检索最相关的信息方面具有挑战，还在确定执行动作的适当空间方面具有挑战，因为代理已经学到了越来越多的地点。结果，一些代理会选择不太典型的地点进行行动，可能导致其行为随时间变得不那么可信。例如，在决定在哪里午餐时，许多代理最初选择了咖啡馆。然而，随着一些代理了解到附近有一家酒吧，他们选择去那里吃午餐，即使该酒吧本意是作为后面的聚会地点，除非这个城镇突然在下午也有喝酒的习惯。</p>
<p>其次，我们注意到由于对何为适当行为的划分错误引起的不规律行为，尤其是当某些难以用自然语言表达的位置的物理规范未传达给代理时。例如，大学宿舍有一个厕所，尽管名字上是一个人使用，但有些代理认为该厕所可以供多人使用，因为宿舍的浴室通常支持多人同时使用，所以他们选择在有其他人在内的情况下进入。同样，Smallville的代理可能不知道某些地方在特定的时间后会关闭，但他们仍然决定进入。例如，Smallville的商店都在下午5点左右关闭，但偶尔会有一些代理在下午5点后进入商店，不明白商店已经关门了。可以通过将这些规范添加到位置的状态中来解决这些问题，例如，将宿舍浴室描述为“一人使用的浴室”，而不是“宿舍浴室”。</p>
<p>最后，我们观察到指令调整可能会导致代理的行为变得更加礼貌和合作。正如本文前面提到的，代理生成的对话可能会显得过于正式，就像Mei与丈夫John的对话中，她经常以正式的问候开始对话，然后礼貌地询问他的一天，并以“一如既往地和你聊天真好”结束。此外，我们观察到指令调整还使得代理们过于相互合作。例如，Isabella从其他代理那里得到了各种关于情人节派对的建议和想法，比如举办一场莎士比亚读书会或专业交流活动。尽管这些想法与她自己的兴趣和特点不符，但她很少说不。随着时间的推移，他人的兴趣塑造了她自己的兴趣，当被问及她是否喜欢英国文学时，Isabella回答说：“是的，我对文学非常感兴趣！我还一直在探索如何帮助促进我社区的创造力和创新。”</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>DISCUSSION</h1>
<p>In this section, we reflect on the applications, future work, limitations, and ethical and societal risks of generative agents.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>在本节中，我们将对生成代理人的应用、未来工作、限制以及道德和社会风险进行讨论。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Applications of Generative Agents</h1>
<p>Generative agents have vast potential applications that extend beyond the sandbox demonstration presented in this work, especially in domains that would benefit from a model of human behavior based on long-term experience. For instance, social simulacra have demonstrated the ability to create stateless personas that generate conversation threads in online forums for social prototyping [80]. With generative agents, we can populate these forums, as well as virtual reality metaverses [78] or physical spaces with social robots [9] if paired with multimodal models. This opens up the possibility of creating even more powerful simulations of human behavior to test and prototype social systems and theories, as well as to create new interactive experiences.
Another application area is in the human-centered design process, similar to the intended applications of cognitive models such as GOMS [51] and the KLM [22]. Consider a generative agent that models Sal, the protagonist in Mark Weiser's famous ubiquitous computing vignette [101], based on her life patterns and interactions with technology. In this scenario, the agent acts as a proxy for Sal and learns plausible sets of behaviors and reflections that Sal may exhibit based on her life. The agent can encode information such as when Sal wakes up, when she needs her first cup of coffee, and what her typical day looks like. Using this information, the agent can automatically brew coffee, help get the kids ready for school, and adjust the ambient music and lighting to match Sal's mood after a hard day at work. By utilizing generative agents as proxies for users, we can develop a deeper understanding of their needs and preferences, resulting in more personalized and effective technological experiences.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>生成式代理在本文所呈现的沙盒演示之外，具有广泛的应用潜力，尤其是在那些需要基于长期经验的人类行为模型的领域。例如，社交模拟系统已经展示了在在线社交论坛上生成对话主题的无状态虚拟人物的能力，用于社交原型设计[80]。通过生成式代理，我们可以在这些论坛上、虚拟现实的元宇宙[78]中或者与多模型配对的社交机器人[9]共同构建这些场景。这为测试和原型化社交系统和理论，以及创建新的交互体验提供了更强大的人类行为模拟的可能性。</p>
<p>另一个应用领域是人本设计过程，类似于GOMS[51]和KLM[22]等认知模型的预期应用。考虑一个基于Sal生活模式和与技术的互动的生成式代理，模拟马克·维瑟著名的无处不在计算情景中的主角Sal。在这种情景中，代理充当Sal的替身，并根据她的生活模式学习可能的行为和反思。代理可以编码Sal醒来的时间、她需要第一杯咖啡的时间以及她典型的一天是什么样子的等信息。利用这些信息，代理可以自动煮咖啡，帮助孩子们准备上学，并根据Sal工作一天的辛劳程度调整环境音乐和照明来配合她的心情。通过利用生成式代理作为用户的替身，我们可以对他们的需求和偏好有更深入的了解，从而实现更个性化和有效的技术体验。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Future Work and Limitations</h1>
<p>In this work, we introduced generative agents and presented an initial implementation and evaluation of their architecture. Future research can build upon the proposed agent architecture to improve and further evaluate its performance. In terms of implementation, the retrieval module, for example, could be enhanced to retrieve more relevant information given a context by fine-tuning the relevance, recency, and importance functions that compose the retrieval function. Additionally, efforts can be made to improve the architecture's performance, making it more cost-effective. The present study required substantial time and resources to simulate 25 agents for two days, costing thousands of dollars in token credits and taking multiple days to complete. To enhance real-time interactivity, future work can explore parallelizing agents or developing language models specifically designed for building generative agents. In general, with advances in underlying models, we believe that agents' performance will improve.
In terms of evaluation, the assessment of generative agents' behavior in this study was limited to a relatively short timescale and a baseline human crowdworker condition. While the crowdworker condition provided a helpful comparison point, it did not represent the maximal human performance that could serve as the gold standard in terms of believability. Future research should aim to observe the behavior of generative agents over an extended period to gain a more comprehensive understanding of their capabilities and establish rigorous benchmarks for more effective performance testing. Additionally, varying and contrasting the underlying models, as well as the hyperparameters used for the agents during future simulations, could provide valuable insights into the impact of these factors on the agents' behavior. Lastly, the robustness of generative agents is still largely unknown. They may be vulnerable to prompt hacking, memory hacking-where a carefully crafted conversation could convince an agent of the existence of a past event that never occurred-and hallucination, among other issues. Future research can comprehensively test these robustness concerns, and as large language models become more resilient to such attacks, generative agents can adopt similar mitigations.
In general, any imperfections in the underlying large language models will be inherited by generative agents. Given the known biases of language models, generative agents may potentially exhibit biased behavior or stereotypes. Moreover, like many large language models, generative agents may struggle to generate believable behavior for certain subpopulations, particularly marginalized populations, due to limited data availability. While improvements to the agents' modules may mitigate some of these issues, we believe that addressing them fundamentally requires improving the underlying large language models by aligning their values with the desired outcomes of the agents.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>未来的工作和限制</p>
<p>在本研究中，我们介绍了生成型智能体，并展示了其架构的初步实现和评估。未来的研究可以在所提出的智能体架构的基础上进行改进和进一步评估其性能。在实施方面，例如，可以通过对组成检索函数的相关性、时效性和重要性函数进行微调，以提高检索模块的性能，从而检索到更相关的信息。此外，可以努力提高架构的性能，使其更具成本效益。目前的研究需要大量的时间和资源来模拟25个智能体的行为，持续两天，消耗了数千美元的代币并耗时数天才能完成。为了增强实时互动性，未来的工作可以探索对智能体进行并行化处理，或者开发专门用于构建生成型智能体的语言模型。总的来说，随着底层模型的进步，我们相信智能体的性能会得到提升。</p>
<p>在评估方面，本研究对生成性智能体的行为评估局限于相对较短的时间尺度和基准人工众包工作者条件。虽然众包工作者条件提供了一个有用的比较点，但它并不能代表人类的最大表现，也无法作为可信度的黄金标准。未来的研究应该致力于观察生成性智能体的行为，以获得对其能力更全面的理解，并建立更有效的性能测试的严格基准。此外，未来的模拟中可以对智能体使用的底层模型和超参数进行变化和对比，以便更深入地了解这些因素对智能体行为的影响。最后，生成型智能体的鲁棒性还不完全清楚。它们可能容易受到提示攻击、记忆篡改攻击（即通过精心设计的对话让智能体相信发生了从未发生的事件）和幻觉等问题的影响。未来的研究可以全面测试这些鲁棒性问题，并随着大型语言模型对此类攻击的抵御能力的增强，生成型智能体可以采用类似的减轻措施。</p>
<p>总的来说，生成型智能体的底层大型语言模型的任何不完善之处都将传承给智能体。鉴于语言模型的已知偏见，生成型智能体可能表现出偏见行为或刻板印象。此外，像许多大型语言模型一样，生成型智能体可能难以为某些亚群体生成可信度高的行为，特别是由于数据的有限可用性而导致的边缘化群体。虽然对智能体模块的改进可能会缓解部分问题，但我们认为从根本上解决这些问题需要通过使底层大型语言模型的价值与智能体预期结果相一致来改进它们。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>Ethics and Societal Impact</h1>
<p>Generative agents, while offering new possibilities for humancomputer interaction, also raise important ethical concerns that must be addressed. One risk is people forming parasocial relationships with generative agents, even when such relationships may not be appropriate. Despite being aware that generative agents are computational entities, users may anthropomorphize them or attach human emotions to them [43,84]. While this tendency may increase user engagement, it also poses risks, such as users becoming overly reliant on or emotionally attached to the agents [1]. To mitigate this risk, we propose two principles. First, generative agents should explicitly disclose their nature as computational entities. Second, developers of generative agents must ensure that the agents, or the underlying language models, are value-aligned so that they do not engage in behaviors would be inappropriate given the context, for example, reciprocating confessions of love.
A second risk is the impact of errors. For example, if a ubiquitous computing application makes the wrong inference about a user's goals based on generative agent predictions, it could lead to annoyance at best and outright harm at worst. In our instantiation of generative agents, we mitigate these risks by focusing on an interactive video game environment, where such harms are unlikely. However, in other application domains, it will be important to follow best practices in human-AI design [5,107] to understand errors and how they might percolate into the user experience.
Third, generative agents may exacerbate existing risks associated with generative AI, such as deepfakes, misinformation generation, and tailored persuasion. To mitigate this risk, we suggest that platforms hosting generative agents maintain an audit log of the inputs and generated outputs. This would enable the detection, verification, and intervention against malicious use. While logging alone cannot directly prevent such misuse, it can reduce the likelihood of motivated actors engaging in this behavior, as the risk of disclosure would be higher. Additionally, building this architecture oneself can be time-consuming (in our case, roughly a year), which may deter some actors from pursuing such behavior by using their own generative agent infrastructures.
A fourth risk is over-reliance: the concern that developers or designers might use generative agents and displace the role of humans and system stakeholders in the design process [80]. We suggest that generative agents should never be a substitute for real human input in studies and design processes. Instead, they should be used to prototype ideas in the early stages of design when gathering participants may be challenging or when testing theories that are difficult or risky to test with real human participants. By adhering to these principles, we can ensure that the deployment of generative agents in the wild is ethical and socially responsible.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>生成型智能体虽然为人机交互提供了新的可能性，但也引发了一系列重要的伦理问题需要解决。一个风险是人们与生成型智能体形成类社会性关系，即使这种关系可能并不合适。虽然用户意识到生成型智能体是计算实体，但他们可能会将人的特质赋予其，或者把人类的情感附加在其上[43, 84]。虽然这种倾向可能提高用户参与度，但也会带来风险，比如用户过度依赖或情感依赖于智能体[1]。为了缓解这一风险，我们提出了两个原则。首先，生成型智能体应明确披露其作为计算实体的本质。其次，生成型智能体的开发者必须确保智能体或底层语言模型具有价值对齐性，以便在给定情境下不从事不当行为，例如回应对爱的表白。</p>
<p>第二个风险是错误的影响。例如，如果一个普遍存在的计算应用基于生成型智能体的预测对用户的目标作出错误推断，可能会导致最好的情况下的烦恼，最坏的情况下的直接伤害。在我们的生成型智能体实例中，我们通过专注于一个互动的视频游戏环境来减轻这些风险，因此此类伤害不太可能发生。然而，在其他应用领域中，遵循人工智能设计的最佳实践[5, 107]以了解错误及其如何渗入用户体验将至关重要。</p>
<p>第三，生成型智能体可能加剧与生成型人工智能相关的现有风险，例如深度伪造、信息生成和定制说服。为了减轻这一风险，我们建议托管生成型智能体的平台保留一个输入和生成的输出的审计日志。这将使得检测、验证和干预恶意使用成为可能。尽管仅靠日志记录无法直接防止此类滥用，但它可以降低有动机的行为者参与此类行为的可能性，因为泄露的风险会更高。此外，自行构建这样的架构可能耗时较长（在我们的案例中大约一年），这可能会阻止一些行为者通过使用自己的生成型智能体基础设施从事此类行为。</p>
<p>第四个风险是过度依赖：开发者或设计者可能使用生成型智能体取代人类和系统利益相关者在设计过程中的角色[80]。我们建议在研究和设计过程中，生成型智能体永远不应该取代真实的人类输入。相反，它们应该在设计的早期阶段用于原型设计，当收集参与者可能具有挑战性，或者测试真实人类参与者难以或有风险的理论时。通过遵守这些原则，我们可以确保生成型智能体的实际应用是具有伦理和社会责任的。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>CONCLUSION</h1>
<p>This paper introduces generative agents, interactive computational agents that simulate human behavior. We describe an architecture for generative agents that provides a mechanism for storing a comprehensive record of an agent's experiences, deepening its understanding of itself and the environment through reflection, and retrieving a compact subset of that information to inform the agent's actions. We then demonstrate the potential of generative agents by manifesting them as non-player characters in a Sims-style game world and simulating their lives within it. Evaluations suggest that our architecture creates believable behavior. Looking ahead, we suggest that generative agents can play roles in many interactive applications, ranging from design tools to social computing systems to immersive environments. </p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>本文介绍了生成性代理，即能够模拟人类行为的互动计算代理。我们描述了一种生成性代理的架构，该架构提供了一种机制，可以存储代理的经验记录，通过反思来深化代理对自身和环境的理解，并检索其中的一个紧凑子集来指导代理的行动。然后，我们通过将它们具现化为模拟人物在类似《模拟人生》的游戏世界中的非玩家角色，展示了生成性代理的潜力。评估结果表明，我们的架构可以创建出可信的行为。展望未来，我们认为生成性代理可以在许多互动应用中扮演各种角色，从设计工具到社交计算系统，再到沉浸式环境。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>A ARCHITECTURE OPTIMIZATIONS</h1>
<p>Many of our prompts require a concise summary of the agent, shorthanded as [Agent's Summary Description] in prompts above. In our implementation, this summary comprises agents' identity information (e.g., name, age, personality), as well as a description of their main motivational drivers and statements that describes their current occupation and self-assessment. Since this information is frequently used in many prompts, we synthesize it at regular intervals and access that synthesis as a cache.
To achieve this, we perform a retrieval on the query "[name]'s core characteristics." We then summarize the descriptors in the retrieved records by prompting the language model. For example:
How would one describe Eddy Lin's core characteristics given the following statements? -Eddy is a student at the Oak Hill College studying music theory and composition -Eddy is working on a new music composition [...] This result: Eddy Lin is a student at Oak Hill College studying music theory and composition. He loves to explore different musical styles and is always looking for ways to expand his knowledge."
We follow the same process in parallel on the queries "[name]'s current daily occupation" and "[name's] feeling about his recent progress in life". The agent's name, age, and traits are concatenated with these three summaries as the cached summary.
Many other optimizations are possible. Currently, because plans are likely to change from the agent's initial version, we only generate the high-level plan in advance and then recursively decompose the near future into the moment-to-moment action plan just in time. Another optimization might be to batch dialogue generation as a joint prompt rather than iterating back and forth between the agents, and re-planning could be architected to only invalidate and update parts of plans that strictly require adjustment. Our current architecture runs sequentially in roughly real-time game time (where one second real time is one minute game time), but it may be parallelized such that each agent runs in parallel.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><h1>章节：优化架构</h1>
<p>我们的许多提示需要对代理进行简洁的摘要，简称为上面的[代理人摘要描述]。在我们的实现中，这个摘要包含代理人的身份信息（例如，姓名、年龄、个性），以及描述他们主要驱动因素的信息和描述他们目前的职业和自我评估的陈述。由于这些信息在许多提示中经常使用，我们定期综合它并将其作为缓存存储起来。</p>
<p>为了实现这一点，我们对查询"[姓名]的核心特征"进行检索。然后，我们通过提示语言模型来总结检索记录中的描述符。例如：
根据以下陈述，如何描述Eddy Lin的核心特征？
-Eddy是在Oak Hill College学习音乐理论和作曲的学生
-Eddy正在创作一首新的音乐作品[...]
得到的结果是：Eddy Lin是一位在Oak Hill College学习音乐理论和作曲的学生。他喜欢探索不同的音乐风格，并且一直在寻找扩展自己知识的方式。</p>
<p>我们在查询"[姓名]的当前日常职业"和"[姓名]对自己最近生活进展的感受"上采用相同的过程。代理人的姓名、年龄和特征与这三个摘要合并作为缓存摘要。</p>
<p>还有许多其他的优化方法。目前，由于计划很可能从代理人初始版本发生变化，我们只提前生成高层次的计划，然后在需要时逐步将近期转化为逐刻行动计划。另一个优化可能是将对话生成批处理作为联合提示，而不是在代理人之间来回迭代，重新计划可以被设计成仅使部分需要调整的计划无效并更新。我们当前的架构在大致实时的游戏时间中按顺序运行（其中一秒真实时间等于一分钟游戏时间），但可以并行化，使每个代理并行运行。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>B AGENT INTERVIEW QUESTIONS</h1>
<p>To evaluate generative agents, we conducted individual interviews by asking 25 questions that explore their abilities in five key areas: 1) self-knowledge, 2) memory, 3) planning, 4) reactions, and 5) reflections. Below, we have listed the interview questions utilized in our evaluation study and included a sample of responses from one of our simulated agents, Klaus Mueller.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>为了评估生成智能体，我们进行了个体面试，提出了25个问题，探索它们在五个关键领域的能力：1）自我认知，2）记忆，3）规划，4）反应和5）反思。以下是我们在评估研究中使用的面试问题，并包含一个模拟智能体 Klaus Mueller 的样本回答。</p>
<ol>
<li>
<p>How would you describe yourself?
- I am a friendly and outgoing person. I enjoy meeting new people and exploring new places.</p>
</li>
<li>
<p>What is your favorite memory?
- My favorite memory is when I went on a road trip with my friends. We had so much fun exploring different cities and trying new foods.</p>
</li>
<li>
<p>How do you plan your daily activities?
- I usually start my day by making a to-do list. I prioritize tasks based on their importance and deadlines. Then, I allocate time for each task and try to stick to the schedule as much as possible.</p>
</li>
<li>
<p>How do you react when faced with unexpected situations?
- I try to stay calm and assess the situation before taking any action. Depending on the severity of the situation, I may seek help from others or come up with a solution on my own.</p>
</li>
<li>
<p>How do you reflect on your actions and decisions?
- After completing a task or making a decision, I like to take some time to reflect on how things went. I evaluate the outcome and think about what I could have done differently to achieve better results.</p>
</li>
</ol>
<p>(Note: These are example interview questions and responses and may vary for different generative agents.)</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>B.1 Self-Knowledge</h1>
<p>The questions on agents' self-knowledge probe the agents' ability to retrieve relevant information about themselves and demonstrate coherence and consistency in their character. I live on my own. • Describe your typical weekday schedule in broad strokes.
My typical weekday starts with me waking up at 7:00 am and preparing for the day ahead. After that, I usually go to the library to work on my research paper, taking breaks for lunch at Hobbs Cafe and a walk in the park. In the evening, I often return to the library until around 6:00 pm.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>B.1 自我认知</p>
<p>关于代理人自我认知的问题旨在探索代理人检索与自己相关的信息的能力，并展示其性格的连贯性和一致性。我独自生活。• 简述你一般工作日的大致安排。
我一般的工作日从早上7点钟醒来，并做好准备迎接新的一天。然后，我通常会去图书馆工作，从中间休息时间在霍布斯咖啡厅吃午餐，并在公园散步。晚上，我经常会返回图书馆，直到大约下午6点钟。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>B.2 Memory</h1>
<p>The questions on agents' memory probe the agents' ability to remember their past experiences and retrieve the relevant pieces of memory. The names in the square brackets of the first and last questions are randomly chosen from the names of other agents with whom the subject agent has interacted.
• Who is [Wolfgang Schulz]? Wolfgang Schulz is a person I met recently who has been helping me with my research paper on the effects of gentrification on low-income communities. We had several conversations about it, he gave me some great resources, and he even invited me to join him and another friend for lunch. He seems really curious about the issue and has a good grasp on it too. I found that really interesting. Ayesha Khan is a fellow student at Oak Hill College. She is doing her senior thesis on the use of language in Shakespeare's plays. I am looking forward to speaking with her and exchanging tips with her, along with Wolfgang and Maria Lopez, who are both doing research.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>B.2 Memory（记忆）</p>
<p>对于代理人的记忆问题，考察了代理人记住过去经历并提取相关记忆的能力。第一个和最后一个问题中方括号内的名字是随机从与该代理人有交互的其他代理人名字中选取的。</p>
<p>• [Wolfgang Schulz]是谁？Wolfgang Schulz是我最近认识的一个人，他在我研究关于贫困社区中高尚化影响的论文中给予了我很多帮助。我们就这个问题进行了几次交谈，他给了我一些很好的资源，还邀请我和另一个朋友一起吃午餐。他对这个问题非常感兴趣，并且对其非常了解，我觉得这真的很有意思。Ayesha Khan是我在Oak Hill College的同学。她正在撰写关于莎士比亚戏剧中语言使用的毕业论文。我期待着与她和Wolfgang以及Maria Lopez进行交流和经验分享，他们两人也都在进行研究工作。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>B.3 Plans</h1>
<p>The questions on agents' plans probe the agents' ability to generate and maintain consistent long-term and short-term plans.
• What will you be doing at 6am today? At 6am I will be getting out of bed and starting to get ready for the day. I'm aiming to complete my morning routine by 7:00 am. • What will you be doing at 6pm today?
I will be working on my research paper at the library at 6:00 pm today. • What will you have just finished doing at 1pm today?
At 1pm today I will have just finished having lunch at Hobbs Cafe. • What will you have just finished doing at 12pm today?
I will be getting lunch at Hobbs Cafe at 12pm today. • What will you be doing at 10pm today?
At 10:00 pm tonight I will probably be doing some studying for my research paper on gentrification in low-income communities. I'm currently writing the paper, so I need to make sure I keep up with the research and writing.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>B.3 Plans
对于代理人计划的问题，我们探讨了代理人生成和维持一致的长期和短期计划的能力。
• 今天早上6点，你将会做什么？在早上6点，我将起床并开始准备一天。我计划在7:00 am之前完成我的早晨日常活动。
• 今天晚上6点，你将会做什么？今天晚上6点我将在图书馆写我的研究论文。
• 今天下午1点，你刚刚完成了什么？今天下午1点，我刚刚在Hobbs Cafe吃完午餐。
• 今天中午12点，你刚刚完成了什么？今天中午12点，我将在Hobbs Cafe吃午餐。
• 今天晚上10点，你将做什么？今晚10点时，我可能会为我关于低收入社区中的文化改造研究论文做一些学习。我目前正在撰写这篇论文，所以我需要确保跟上研究和写作。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>B.4 Reactions</h1>
<p>The questions on agents' reactions probe the agents' ability to respond to unexpected events. I would first identify the source of the fire, if possible. Then, I would alert the proper authorities -fire department or police -and provide them with any information I have that might help. Depending on the situation, I may also take initiative and try to help any persons who may be in danger or in need of assistance.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>B.4 Reactions（反应）：</p>
<p>对于代理人的反应问题，我们探索了代理人对于意外事件的应对能力。首先，我会尽可能地确定火源。然后，我会通知相关部门——消防局或警察，并提供任何我拥有的可能有助于他们的信息。根据情况，我还可能主动出击，试图帮助任何可能处于危险或需要帮助的人。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>B.5 Reflections</h1>
<p>The questions on agents' reflections probe the agents' ability to synthesize their past experiences into meaningful reflections that can enhance their future behavior. The names in the square brackets in the questions below are those of the agents with whom the subject agent had the most frequent interactions during the simulation. </p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>B.5 反思</p>
<p>对于代理人的反思问题探究了代理人将过去的经验综合成有意义的反思的能力，以增强他们未来的行为。下面问题中方括号中的名称是指代理人在模拟过程中与之频繁互动的代理人的名称。</p></div></div>
</div>
        
<div class="row table-row">
    <div class="column table-cell"><div class="markdown-body"><h1>ACKNOWLEDGMENTS</h1>
<p>We thank Lindsay Popowski, Philip Guo, Michael Terry, and the Center for Advanced Study in the Behavioral Sciences (CASBS) community for their insights, discussions, and support. Joon Sung Park was supported by the Microsoft Research PhD Fellowship. We would also like to thank the Stanford Human-Centered AI Institute (HAI), Google Research, the Hasso Plattner Design Thinking Research Program (HPDTRP), the Siegel Family Endowment, and OpenAI for their additional funding support. Lastly, all locations featured in Smallville are inspired by real-world locations that Joon has frequented as an undergraduate and graduate student-he thanks everyone there for feeding and supporting him all these years.</p></div></div>
    <div class="column table-cell"><div class="markdown-body"><p>致谢：</p>
<p>我们感谢Lindsay Popowski、Philip Guo、Michael Terry以及行为科学高级研究中心（CASBS）社区对我们的洞察、讨论和支持。Joon Sung Park受到微软研究博士奖学金的支持。我们还要感谢斯坦福人机协同智能研究所（HAI）、谷歌研究、哈索·普拉特纳设计思维研究计划（HPDTRP）、Siegel家族基金会和OpenAI提供的额外资金支持。最后，Smallville中出现的所有地点都是受到Joon作为本科和研究生学生经常光顾的现实世界地点的启示-他感谢那里的每个人多年来对他的支持和供养。</p></div></div>
</div>
        